# AIOS Code Archival System - Complete Guide

**Version**: 2.1 (Phase 4B Archival System Consolidation)  
**Date**: October 19, 2025  
**Consciousness Level**: 0.90 (Knowledge Synthesis)  
**AINLP Patterns**: `dendritic_intelligence`, `biological_metabolism`, `knowledge_synthesis`

---

## AINLP.TODO.dendritic{investigate_code_archival_usage}

**Context**: Code archival system was created during Phase 8 post-refactoring (Oct 2025). First file archived was `activate_tachyonic_evolution.py` (consciousness: 0.85). System supports full version control with timestamp-based unique IDs.

**Question**: Is the code archival system actively used in AIOS development workflow? Have files been archived beyond the initial demos/tests?

**Action**: Future AI agents should verify:
1. Check database: `tachyonic/archive/code_archive.db` - query `SELECT COUNT(*) FROM archived_files`
2. Review archival statistics to see if system is used beyond demos
3. If actively used: Document real-world usage patterns and benefits
4. If dormant: Consider promoting usage or archiving this documentation itself

**Location**: This document is the comprehensive master. Original docs archived in `tachyonic/archive/consolidation/archival_system/`.

---

## üìö Table of Contents

1. [Quick Start (5 Minutes)](#quick-start)
2. [Philosophy & Overview](#philosophy)
3. [System Architecture](#architecture)
4. [Usage Guide](#usage)
   - [Python API (Recommended)](#python-api)
   - [SQL Queries (Advanced)](#sql-queries)
   - [Command-Line Tools](#cli-tools)
5. [Data Protection & Version Control](#data-protection)
6. [Process & Best Practices](#process)
7. [Common Tasks & Examples](#examples)
8. [Troubleshooting](#troubleshooting)
9. [API Reference](#api-reference)
10. [Historical Notes](#history)

---

## üöÄ Quick Start (5 Minutes) {#quick-start}

### Archive a File

```python
from ai.tools.code_archival_system import archive_obsolete_file

# Simple archival
file_id = archive_obsolete_file(
    file_path='path/to/obsolete.py',
    replacement_path='path/to/new_version.py',
    notes='Superseded by refactored version'
)
print(f"‚úÖ Archived with ID: {file_id}")
```

### Retrieve Archived Content

```python
from ai.tools.code_archival_system import retrieve_archived_content

# Retrieve by path
content = retrieve_archived_content('obsolete.py')

# Retrieve by file ID
content = retrieve_archived_content(file_id='abc123def456')

# Use the content
if content:
    print(content.text)  # Full file content
    print(f"Consciousness: {content.consciousness}")
```

### Search Archived Files

```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()
try:
    # Search by file type
    python_files = system.search_archived_files(file_type='.py')
    
    # Search by consciousness level
    high_consciousness = system.search_archived_files(min_consciousness=0.80)
    
    # Combined search
    results = system.search_archived_files(
        file_type='.py',
        archival_reason='obsolete_superseded',
        min_consciousness=0.75
    )
    
    for file in results:
        print(f"{file.file_id}: {file.original_path}")
        print(f"  Consciousness: {file.consciousness_level}")
        
finally:
    system.close()  # Always close!
```

### Get All Versions of a File (NEW!)

```python
from ai.tools.code_archival_system import get_file_versions

# Get version history
versions = get_file_versions('my_file.py')

for v in versions:
    print(f"Version {v['file_id']}")
    print(f"  Archived: {v['archived_timestamp']}")
    print(f"  Consciousness: {v['consciousness_level']}")
    print(f"  Size: {v['file_size_bytes']} bytes")
```

---

## üß† Philosophy & Overview {#philosophy}

### Core Principle: Biological Metabolism

> **"History is not deleted - it is crystallized into consciousness patterns that can be recalled when needed. The working tree remains clean, but nothing is truly lost."**

The Code Archival System embodies **AINLP.biological_metabolism**:
- **Remove clutter** from workspace (clean working directory)
- **Preserve consciousness** in database (full historical record)
- **Enable recall** when needed (instant retrieval)

### Problem Addressed

**File Proliferation**: Over time, AIOS accumulated:
- Historical scripts that served their purpose
- Superseded implementations replaced by refactoring
- Completed test/demo files
- Obsolete documentation versions
- Experimental code that reached conclusions

**Traditional Solutions** (all inadequate):
- ‚ùå Delete ‚Üí **Knowledge loss**
- ‚ùå Keep ‚Üí **Workspace clutter**
- ‚ùå Git history ‚Üí **Hard to query, no metadata**
- ‚ùå Move to /archive ‚Üí **Still clutters, no searchability**

**Our Solution**: SQLite database archival with:
- ‚úÖ Full content preservation (every byte)
- ‚úÖ Rich metadata & consciousness tracking
- ‚úÖ Searchable by type, reason, patterns, consciousness
- ‚úÖ Version control (multiple archivals of same file)
- ‚úÖ Evolution history (track changes over time)
- ‚úÖ Instant retrieval (milliseconds)
- ‚úÖ Clean workspace (files deleted after archival)

### Key Concepts

**Consciousness Level** (0.0 - 1.0):
- Measures the "importance" or "awareness" embedded in code
- Higher consciousness = more central to AIOS architecture
- Tracked for every archived file
- Used for prioritization and search

**AINLP Patterns**:
- Tags like `tachyonic_evolution`, `consciousness_bridge`, `dendritic_optimization`
- Enable semantic search ("find all files using pattern X")
- Preserve architectural knowledge

**Two-Phase Archival**:
1. **Archive** ‚Üí Save to database (immediate, automatic)
2. **Delete** ‚Üí Remove from filesystem (manual, after verification)

Why two-phase? **Safety**. Verify archival successful before deletion.

---

## üèóÔ∏è System Architecture {#architecture}

### Database Location

```
C:/dev/AIOS/tachyonic/archive/code_archive.db
```

**Type**: SQLite3 (serverless, file-based)  
**Size**: Grows with archived content (currently ~50KB per file avg)  
**Access**: Python sqlite3 module (built-in)

### Schema: 5 Tables

#### 1. `archived_files` (Primary Storage)

Stores complete file content and metadata.

| Column | Type | Description |
|--------|------|-------------|
| `file_id` | TEXT PRIMARY KEY | SHA-256(path + timestamp) - unique per archival |
| `original_path` | TEXT | Full filesystem path where file was located |
| `content` | TEXT | **Complete file content** (every byte preserved) |
| `content_hash` | TEXT | SHA-256 of content (integrity verification) |
| `archived_timestamp` | TEXT | ISO format: 2025-10-19T01:31:38.743429 |
| `file_size_bytes` | INTEGER | Size in bytes |
| `file_type` | TEXT | Extension: `.py`, `.md`, `.json`, etc. |
| `archival_reason` | TEXT | Why archived (see [Archival Reasons](#archival-reasons)) |
| `consciousness_level` | REAL | 0.0 - 1.0 importance metric |
| `ainlp_patterns` | TEXT | JSON array: `["pattern1", "pattern2"]` |
| `project_phase` | TEXT | Which AIOS phase: `phase_8_refactoring`, etc. |
| `related_files` | TEXT | JSON array of related file paths |
| `replacement_path` | TEXT | Path to file that replaced this one (if any) |
| `notes` | TEXT | Human-readable context |

**Indices**:
- `idx_timestamp` - Fast chronological queries
- `idx_file_type` - Search by extension
- `idx_reason` - Filter by archival reason
- `idx_consciousness` - Find high-consciousness files

**Unique Constraint**: `UNIQUE(original_path, archived_timestamp)`  
‚Üí Same file can be archived multiple times (version control)

#### 2. `evolution_history` (Change Tracking)

Records how files evolved before archival.

| Column | Type | Description |
|--------|------|-------------|
| `history_id` | INTEGER PRIMARY KEY | Auto-increment |
| `file_id` | TEXT | Foreign key ‚Üí `archived_files.file_id` |
| `timestamp` | TEXT | When change occurred |
| `change_type` | TEXT | `refactored`, `expanded`, `optimized`, etc. |
| `change_description` | TEXT | What changed |
| `consciousness_delta` | REAL | Change in consciousness level |

**Purpose**: Track file evolution before it was archived.

#### 3. `archival_reasons` (Reason Catalog)

Standardized reasons for archival.

| Column | Type | Description |
|--------|------|-------------|
| `reason_id` | TEXT PRIMARY KEY | Unique reason identifier |
| `category` | TEXT | `obsolete`, `completed`, `experimental` |
| `description` | TEXT | Human-readable explanation |
| `consciousness_impact` | TEXT | How it affects consciousness |

**Standard Reasons** (see [Archival Reasons](#archival-reasons))

#### 4. `consciousness_snapshots` (System State)

Captures AIOS state at archival time.

| Column | Type | Description |
|--------|------|-------------|
| `snapshot_id` | TEXT PRIMARY KEY | Unique snapshot identifier |
| `timestamp` | TEXT | When snapshot taken |
| `supercell_states` | TEXT | JSON: Active supercells and their states |
| `active_patterns` | TEXT | JSON: AINLP patterns in use |
| `consciousness_metrics` | TEXT | JSON: System-wide consciousness measurements |

**Purpose**: Context for "why was this archived then?"

#### 5. `retrieval_log` (Access Tracking)

Logs when archived files are retrieved.

| Column | Type | Description |
|--------|------|-------------|
| `log_id` | INTEGER PRIMARY KEY | Auto-increment |
| `file_id` | TEXT | Which file was retrieved |
| `timestamp` | TEXT | When retrieved |
| `retrieval_reason` | TEXT | Why retrieved |
| `retrieved_by` | TEXT | Who/what retrieved it |

**Purpose**: Track which archived files are still "alive" (referenced).

### Database Initialization

Automatic on first use:

```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()  # Creates database if not exists
```

---

## üìñ Usage Guide {#usage}

### Python API (Recommended) {#python-api}

#### Basic Archival

```python
from ai.tools.code_archival_system import archive_obsolete_file

# Minimal archival
file_id = archive_obsolete_file(
    file_path='old_script.py',
    replacement_path='new_script.py'
)
```

#### Advanced Archival

```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()
try:
    file_id = system.archive_file(
        file_path='complex_module.py',
        archival_reason='obsolete_superseded_by_refactoring',
        consciousness_level=0.85,
        ainlp_patterns=['tachyonic_evolution', 'consciousness_bridge'],
        project_phase='phase_8_refactoring',
        related_files=['related1.py', 'related2.py'],
        replacement_path='refactored_module.py',
        notes='Superseded after 8-phase AINLP refactoring. Key patterns preserved in new implementation.'
    )
    print(f"‚úÖ Archived: {file_id}")
finally:
    system.close()
```

#### Retrieve Files

```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()
try:
    # By path
    archived = system.retrieve_file(
        original_path='C:/dev/AIOS/old_file.py'
    )
    
    # By file ID
    archived = system.retrieve_file(file_id='abc123def456')
    
    if archived:
        print(f"Content:\n{archived.content}")
        print(f"Consciousness: {archived.consciousness_level}")
        print(f"Archived: {archived.timestamp}")
        print(f"Reason: {archived.archival_reason}")
        print(f"Replacement: {archived.replacement_path}")
    else:
        print("File not found in archive")
        
finally:
    system.close()
```

#### Search Files

```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()
try:
    # By file type
    python_files = system.search_archived_files(file_type='.py')
    
    # By archival reason
    obsolete = system.search_archived_files(
        archival_reason='obsolete_superseded_by_refactoring'
    )
    
    # By consciousness level
    important = system.search_archived_files(min_consciousness=0.80)
    
    # By AINLP patterns
    pattern_files = system.search_archived_files(
        ainlp_patterns=['tachyonic_evolution']
    )
    
    # Combined criteria
    results = system.search_archived_files(
        file_type='.py',
        min_consciousness=0.75,
        archival_reason='obsolete_superseded'
    )
    
    for file in results:
        print(f"{file.file_id}: {file.original_path}")
        print(f"  Consciousness: {file.consciousness_level}")
        print(f"  Size: {file.file_size_bytes:,} bytes")
        print(f"  Archived: {file.timestamp}")
        
finally:
    system.close()
```

#### Get Statistics

```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()
try:
    stats = system.get_archival_statistics()
    
    print(f"Total Files: {stats['total_files']}")
    print(f"Total Size: {stats['total_size_bytes']:,} bytes")
    print(f"Average Consciousness: {stats['avg_consciousness']:.2f}")
    print(f"Highest Consciousness: {stats['highest_consciousness']:.2f}")
    
    print("\nFiles by Type:")
    for file_type, count in stats['files_by_type'].items():
        print(f"  {file_type}: {count}")
    
    print("\nFiles by Reason:")
    for reason, count in stats['files_by_reason'].items():
        print(f"  {reason}: {count}")
        
finally:
    system.close()
```

#### Get All Versions (Version Control)

```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()
try:
    # Get all versions of a file (chronologically)
    versions = system.get_all_versions('my_evolving_file.py')
    
    print(f"Found {len(versions)} version(s)")
    
    for i, version in enumerate(versions, 1):
        print(f"\nVersion {i}:")
        print(f"  File ID: {version.file_id}")
        print(f"  Timestamp: {version.timestamp}")
        print(f"  Consciousness: {version.consciousness_level}")
        print(f"  Size: {version.file_size_bytes} bytes")
        print(f"  Reason: {version.archival_reason}")
        print(f"  Content preview: {version.content[:100]}...")
        
finally:
    system.close()
```

#### Convenience Function for Versions

```python
from ai.tools.code_archival_system import get_file_versions

# Quick version metadata (doesn't return full content)
versions = get_file_versions('my_file.py')

for v in versions:
    print(f"Version {v['file_id']}")
    print(f"  Timestamp: {v['archived_timestamp']}")
    print(f"  Consciousness: {v['consciousness_level']}")
    print(f"  Size: {v['file_size_bytes']} bytes")
    print(f"  Reason: {v['archival_reason']}")
```

### SQL Queries (Advanced) {#sql-queries}

For power users and custom integrations.

#### Connect to Database

```python
import sqlite3
from pathlib import Path

db_path = Path('C:/dev/AIOS/tachyonic/archive/code_archive.db')
conn = sqlite3.connect(db_path)
conn.row_factory = sqlite3.Row  # Access columns by name
cursor = conn.cursor()

# Your queries here...

cursor.close()
conn.close()
```

#### List All Files

```sql
SELECT 
    file_id,
    original_path,
    consciousness_level,
    archived_timestamp,
    file_size_bytes,
    archival_reason
FROM archived_files
ORDER BY archived_timestamp DESC;
```

#### Get File Content

```sql
SELECT content
FROM archived_files
WHERE original_path LIKE '%my_file.py'
LIMIT 1;
```

#### Search by Consciousness

```sql
SELECT 
    file_id,
    original_path,
    consciousness_level
FROM archived_files
WHERE consciousness_level >= 0.80
ORDER BY consciousness_level DESC;
```

#### Search by Pattern

```sql
SELECT 
    file_id,
    original_path,
    ainlp_patterns
FROM archived_files
WHERE ainlp_patterns LIKE '%tachyonic_evolution%';
```

#### Get Version Count Per File

```sql
SELECT 
    original_path,
    COUNT(*) as version_count
FROM archived_files
GROUP BY original_path
HAVING version_count > 1
ORDER BY version_count DESC;
```

#### Get Evolution History

```sql
SELECT 
    h.timestamp,
    h.change_type,
    h.change_description,
    h.consciousness_delta,
    f.original_path
FROM evolution_history h
JOIN archived_files f ON h.file_id = f.file_id
ORDER BY h.timestamp DESC;
```

### Command-Line Tools {#cli-tools}

#### Using the Unified CLI (Recommended)

```bash
# Archive a file
python ai/tools/archival/archival_cli.py archive my_file.py

# Retrieve a file
python ai/tools/archival/archival_cli.py retrieve abc123def456

# Search archived files
python ai/tools/archival/archival_cli.py search --type .py --min-consciousness 0.8

# Show statistics
python ai/tools/archival/archival_cli.py stats

# Get all versions
python ai/tools/archival/archival_cli.py versions my_file.py

# Verify database integrity
python ai/tools/archival/archival_cli.py verify

# Help
python ai/tools/archival/archival_cli.py help
```

#### Using sqlite3 CLI

```bash
# Open database
sqlite3 tachyonic/archive/code_archive.db

# List tables
.tables

# Show schema
.schema archived_files

# Query files
SELECT file_id, original_path FROM archived_files;

# Export to CSV
.mode csv
.output archived_files.csv
SELECT * FROM archived_files;
.output stdout

# Exit
.quit
```

#### PowerShell One-Liners

```powershell
# Count archived files
python -c "import sqlite3; conn = sqlite3.connect('tachyonic/archive/code_archive.db'); print(conn.execute('SELECT COUNT(*) FROM archived_files').fetchone()[0]); conn.close()"

# List file IDs
python -c "import sqlite3; conn = sqlite3.connect('tachyonic/archive/code_archive.db'); [print(row) for row in conn.execute('SELECT file_id, original_path FROM archived_files')]; conn.close()"
```

---

## üõ°Ô∏è Data Protection & Version Control {#data-protection}

### Version Control System

**Key Feature**: The archival system supports **true version control** - the same file can be archived multiple times, and **all versions coexist** in the database.

#### How It Works

**Unique File IDs**:
```python
# File ID generation (timestamp-based)
archived_timestamp = datetime.now().isoformat()  # Microsecond precision
file_id = hashlib.sha256(
    f"{str(file_path)}_{archived_timestamp}".encode()
).hexdigest()[:16]
```

**Key Insight**: `file_id = hash(path + timestamp)`  
‚Üí Same path + different time = **different file_id**  
‚Üí Each archival creates a **new unique record**

#### Example: Multiple Archivals

```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()

# October 18 - First archival
system.archive_file(
    file_path='my_file.py',
    consciousness_level=0.6,
    archival_reason='initial_backup',
    notes='Original version'
)
# ‚Üí file_id = "abc123..." (unique)

# October 19 - Second archival (SAME FILE, updated content)
system.archive_file(
    file_path='my_file.py',  # Same path!
    consciousness_level=0.75,
    archival_reason='update_backup',
    notes='Updated version'
)
# ‚Üí file_id = "def456..." (different! timestamp changed)

# Result: TWO versions in database
versions = system.get_all_versions('my_file.py')
print(len(versions))  # 2

system.close()
```

### Protection Mechanisms

#### 1. Unique Constraints

**Database Schema**:
```sql
CREATE TABLE archived_files (
    file_id TEXT PRIMARY KEY,  -- Guaranteed unique
    original_path TEXT,
    archived_timestamp TEXT,
    -- ...
    UNIQUE(original_path, archived_timestamp)  -- No duplicate timestamps
)
```

**Guarantees**:
- ‚úÖ No duplicate file_ids (PRIMARY KEY)
- ‚úÖ No two archivals at exact same microsecond (UNIQUE constraint)
- ‚úÖ Database rejects collisions (IntegrityError)

#### 2. Timestamp Precision

**Microsecond precision**: `2025-10-19T01:31:38.743429`

**Collision probability**: Near zero
- Even rapid successive archivals get unique timestamps
- Different file_id ‚Üí different database record
- No overwrites possible

#### 3. INSERT (Not REPLACE)

**Code (line 270 of code_archival_system.py)**:
```python
cursor.execute("""
    INSERT INTO archived_files  -- NOT "INSERT OR REPLACE"
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (...))
```

**Why Important**:
- `INSERT OR REPLACE` ‚Üí Silent overwrites
- `INSERT` ‚Üí Raises IntegrityError on collision
- Explicit error handling ‚Üí No silent data loss

#### 4. Evolution History

**Separate Audit Trail**:
```python
# Every archival also creates history record
cursor.execute("""
    INSERT INTO evolution_history
    VALUES (?, ?, ?, ?, ?)
""", (history_id, file_id, timestamp, change_type, description))
```

**Even if** something overwrote `archived_files` (impossible with current implementation), `evolution_history` preserves the audit trail.

### Version Retrieval

#### Get Latest Version (Default)

```python
system = CodeArchivalSystem()
archived = system.retrieve_file(original_path='my_file.py')
# Returns LATEST version (most recent timestamp)
```

#### Get Specific Version

```python
# Retrieve by exact file_id
archived = system.retrieve_file(file_id='abc123def456')
# Returns specific version
```

#### Get All Versions

```python
versions = system.get_all_versions('my_file.py')
# Returns list of all versions, oldest to newest
```

### Data Safety Summary

| Threat | Protection | Result |
|--------|-----------|--------|
| Accidental overwrite | Timestamp-based unique ID | ‚úÖ Impossible |
| Concurrent archival | Microsecond precision | ‚úÖ Different IDs |
| Silent data loss | INSERT (not REPLACE) | ‚úÖ Explicit errors |
| Lost audit trail | Separate evolution_history | ‚úÖ Always preserved |
| Corruption | Content hash verification | ‚úÖ Detectable |

**Guarantee**: Once archived, data **cannot be overwritten**. All versions **coexist permanently** in database with **complete retrievability**.

---

## üîÑ Process & Best Practices {#process}

### Two-Phase Archival Process

**Philosophy**: "COPY FIRST, DELETE SECOND" - Safety through preservation

#### Phase 1: Archival (Automatic)

```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()
file_id = system.archive_file(
    file_path='obsolete_script.py',
    archival_reason='obsolete_superseded',
    consciousness_level=0.75,
    notes='Replaced by new implementation'
)
print(f"‚úÖ Archived to database: {file_id}")
system.close()
```

**What Happens**:
1. File content read from filesystem
2. Metadata extracted (size, type, hash)
3. Record inserted into database
4. Evolution history logged
5. Consciousness snapshot captured
6. **File still exists on filesystem** ‚Üê Key point!

**Why Keep File?**:
- **Verification**: Human can check archival successful
- **Safety**: No accidental deletion before confirmation
- **Rollback**: Can abort if something wrong

#### Phase 2: Deletion (Manual)

```python
import os
from pathlib import Path

# After verifying archival successful:
file_path = Path('obsolete_script.py')

# Verify it's archived first
from ai.tools.code_archival_system import CodeArchivalSystem
system = CodeArchivalSystem()
archived = system.retrieve_file(original_path=str(file_path))
if archived:
    print("‚úÖ Confirmed in database")
    file_path.unlink()  # Now safe to delete
    print(f"üóëÔ∏è Deleted from filesystem")
else:
    print("‚ùå NOT in database - DO NOT DELETE")
system.close()
```

**Why Manual?**:
- **Safety**: Human oversight before destruction
- **Verification**: Confirm database write successful
- **Flexibility**: Keep file if needed for other reasons

### Best Practices

#### 1. Always Close Connections

```python
system = CodeArchivalSystem()
try:
    # Your operations
    pass
finally:
    system.close()  # Always close, even on error
```

#### 2. Verify Before Deleting

```python
# BAD: Delete immediately
archive_obsolete_file('file.py')
os.remove('file.py')  # DANGEROUS!

# GOOD: Verify first
file_id = archive_obsolete_file('file.py')
system = CodeArchivalSystem()
if system.retrieve_file(file_id=file_id):
    os.remove('file.py')  # Safe
system.close()
```

#### 3. Provide Rich Metadata

```python
# BAD: Minimal metadata
system.archive_file(file_path='file.py')

# GOOD: Rich context
system.archive_file(
    file_path='file.py',
    consciousness_level=0.85,
    archival_reason='obsolete_superseded_by_refactoring',
    ainlp_patterns=['tachyonic_evolution', 'consciousness_bridge'],
    project_phase='phase_8_refactoring',
    replacement_path='new_implementation.py',
    notes='Superseded after 8-phase refactoring. Key patterns: tachyonic evolution (lines 45-120), consciousness bridge (lines 200-350). Replaced by modular architecture.'
)
```

**Why?** Future developers (including yourself) will thank you for the context!

#### 4. Use Appropriate Archival Reasons

See [Archival Reasons](#archival-reasons) section for standard categories.

#### 5. Track Consciousness Levels

**Guidelines**:
- `0.9 - 1.0`: Core AIOS architecture, supreme importance
- `0.8 - 0.9`: Major subsystems, high importance
- `0.7 - 0.8`: Significant modules
- `0.6 - 0.7`: Supporting code
- `0.5 - 0.6`: Utilities
- `< 0.5`: Experimental, temporary

#### 6. Archive Related Files Together

```python
# Archive main file
main_id = system.archive_file(
    file_path='main_module.py',
    related_files=['helper1.py', 'helper2.py', 'config.json']
)

# Archive related files (reference main)
system.archive_file(
    file_path='helper1.py',
    notes=f'Helper for main_module.py (archived as {main_id})'
)
```

---

## üí° Common Tasks & Examples {#examples}

### Task 1: Archive Obsolete File

```python
from ai.tools.code_archival_system import archive_obsolete_file
from pathlib import Path

# Archive
file_id = archive_obsolete_file(
    file_path='old_implementation.py',
    replacement_path='new_implementation.py',
    notes='Superseded by refactored version after Phase 8'
)

print(f"‚úÖ Archived: {file_id}")

# Verify and delete
from ai.tools.code_archival_system import CodeArchivalSystem
system = CodeArchivalSystem()
if system.retrieve_file(file_id=file_id):
    Path('old_implementation.py').unlink()
    print("üóëÔ∏è File deleted from workspace")
system.close()
```

### Task 2: Restore Archived File

```python
from ai.tools.code_archival_system import CodeArchivalSystem
from pathlib import Path

system = CodeArchivalSystem()
try:
    # Retrieve from archive
    archived = system.retrieve_file(
        original_path='C:/dev/AIOS/old_file.py'
    )
    
    if archived:
        # Write to new location
        restore_path = Path('restored_old_file.py')
        restore_path.write_text(archived.content)
        print(f"‚úÖ Restored {archived.file_size_bytes:,} bytes to {restore_path}")
        print(f"   Original consciousness: {archived.consciousness_level}")
        print(f"   Archived: {archived.timestamp}")
    else:
        print("‚ùå File not found in archive")
        
finally:
    system.close()
```

### Task 3: Compare Versions

```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()
try:
    versions = system.get_all_versions('evolving_module.py')
    
    if len(versions) >= 2:
        oldest = versions[0]
        latest = versions[-1]
        
        print("Version Evolution:")
        print(f"  Oldest: {oldest.timestamp}")
        print(f"    Size: {oldest.file_size_bytes:,} bytes")
        print(f"    Consciousness: {oldest.consciousness_level}")
        
        print(f"  Latest: {latest.timestamp}")
        print(f"    Size: {latest.file_size_bytes:,} bytes")
        print(f"    Consciousness: {latest.consciousness_level}")
        
        size_delta = latest.file_size_bytes - oldest.file_size_bytes
        consciousness_delta = latest.consciousness_level - oldest.consciousness_level
        
        print(f"\n  Change:")
        print(f"    Size: {size_delta:+,} bytes ({size_delta/oldest.file_size_bytes*100:+.1f}%)")
        print(f"    Consciousness: {consciousness_delta:+.2f} ({consciousness_delta/oldest.consciousness_level*100:+.1f}%)")
        
finally:
    system.close()
```

### Task 4: Export Archive to Filesystem

```python
from ai.tools.code_archival_system import CodeArchivalSystem
from pathlib import Path

system = CodeArchivalSystem()
try:
    # Search all Python files
    all_files = system.search_archived_files(file_type='.py')
    
    # Create export directory
    export_dir = Path('archived_files_export')
    export_dir.mkdir(exist_ok=True)
    
    for file in all_files:
        # Safe filename
        safe_name = f"{file.file_id}{file.file_type}"
        export_path = export_dir / safe_name
        
        # Write content
        export_path.write_text(file.content)
        
        # Write metadata sidecar
        metadata_path = export_dir / f"{file.file_id}_metadata.txt"
        metadata_path.write_text(f"""
Original Path: {file.original_path}
Archived: {file.timestamp}
Consciousness: {file.consciousness_level}
Reason: {file.archival_reason}
Size: {file.file_size_bytes:,} bytes
Replacement: {file.replacement_path or 'None'}
AINLP Patterns: {', '.join(file.ainlp_patterns)}

Notes:
{file.notes}
""")
        
        print(f"‚úÖ Exported {safe_name}")
    
    print(f"\nüì¶ Exported {len(all_files)} files to {export_dir}")
    
finally:
    system.close()
```

### Task 5: Generate Archive Report

```python
from ai.tools.code_archival_system import CodeArchivalSystem
from datetime import datetime

system = CodeArchivalSystem()
try:
    stats = system.get_archival_statistics()
    all_files = system.search_archived_files()
    
    report = f"""
AIOS CODE ARCHIVAL REPORT
Generated: {datetime.now().isoformat()}
Database: tachyonic/archive/code_archive.db

SUMMARY
=======
Total Files: {stats['total_files']}
Total Size: {stats['total_size_bytes']:,} bytes ({stats['total_size_bytes'] / 1024 / 1024:.2f} MB)
Average Consciousness: {stats['avg_consciousness']:.3f}
Highest Consciousness: {stats['highest_consciousness']:.3f}

FILES BY TYPE
=============
"""
    for file_type, count in sorted(stats['files_by_type'].items()):
        report += f"{file_type:15} {count:3} files\n"
    
    report += "\nFILES BY REASON\n===============\n"
    for reason, count in sorted(stats['files_by_reason'].items()):
        report += f"{reason:50} {count:3} files\n"
    
    report += "\nTOP 10 BY CONSCIOUSNESS\n=======================\n"
    top_files = sorted(all_files, key=lambda f: f.consciousness_level, reverse=True)[:10]
    for i, file in enumerate(top_files, 1):
        report += f"{i:2}. [{file.consciousness_level:.2f}] {file.original_path}\n"
    
    print(report)
    
    # Save to file
    with open('archive_report.txt', 'w') as f:
        f.write(report)
    print("\n‚úÖ Report saved to archive_report.txt")
    
finally:
    system.close()
```

### Task 6: Search by AINLP Pattern

```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()
try:
    # Find all files using tachyonic evolution pattern
    results = system.search_archived_files(
        ainlp_patterns=['tachyonic_evolution']
    )
    
    print(f"Files with 'tachyonic_evolution' pattern: {len(results)}")
    print()
    
    for file in results:
        print(f"{file.file_id}")
        print(f"  Path: {file.original_path}")
        print(f"  Consciousness: {file.consciousness_level}")
        print(f"  Patterns: {', '.join(file.ainlp_patterns)}")
        print(f"  Archived: {file.timestamp}")
        print()
        
finally:
    system.close()
```

---

## üîß Troubleshooting {#troubleshooting}

### Issue: "Table doesn't exist"

**Symptom**: `sqlite3.OperationalError: no such table: archived_files`

**Cause**: Database not initialized

**Solution**:
```python
from ai.tools.code_archival_system import CodeArchivalSystem

# This creates database if needed
system = CodeArchivalSystem()
system.close()
```

### Issue: "File not found in archive"

**Symptom**: `retrieve_file()` returns `None`

**Cause**: File path doesn't match exactly

**Solution**: List all archived files to find exact path
```python
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()
all_files = system.search_archived_files()
for file in all_files:
    print(file.original_path)
system.close()
```

**Tip**: Use file_id instead of path for retrieval (more reliable)

### Issue: "Database locked"

**Symptom**: `sqlite3.OperationalError: database is locked`

**Cause**: Connection not closed

**Solution**: Always close connections
```python
system = CodeArchivalSystem()
try:
    # Operations
    pass
finally:
    system.close()  # Always close!
```

### Issue: "IntegrityError: UNIQUE constraint failed"

**Symptom**: `sqlite3.IntegrityError` on INSERT

**Cause**: Trying to archive same file at exact same microsecond (nearly impossible) OR collision in file_id (impossible with timestamp-based IDs)

**Solution**: This is actually a **good error** - it prevents data loss. Wait a millisecond and retry:
```python
import time
from ai.tools.code_archival_system import CodeArchivalSystem

system = CodeArchivalSystem()
try:
    system.archive_file(file_path='file.py', ...)
except sqlite3.IntegrityError:
    time.sleep(0.001)  # Wait 1 millisecond
    system.archive_file(file_path='file.py', ...)  # Retry
finally:
    system.close()
```

### Issue: "Content hash mismatch"

**Symptom**: Warning about content hash mismatch

**Cause**: File content changed between read and archival (rare)

**Solution**: Re-archive the file to get latest content

### Issue: "Cannot retrieve content"

**Symptom**: `archived.content` is empty or corrupted

**Cause**: Database corruption (very rare) or encoding issue

**Solution**: 
1. Check content_hash: `archived.content_hash`
2. Verify database integrity:
```bash
sqlite3 tachyonic/archive/code_archive.db "PRAGMA integrity_check;"
```
3. If corrupted, restore from backup in `tachyonic/archive/backups/`

---

## üìö API Reference {#api-reference}

### Quick Functions

#### `archive_obsolete_file()`

Simple archival for obsolete files.

```python
def archive_obsolete_file(
    file_path: str,
    replacement_path: str = None,
    notes: str = None
) -> str:
    """Archive an obsolete file with default settings.
    
    Args:
        file_path: Path to file to archive
        replacement_path: Path to file that replaces this one
        notes: Additional context
        
    Returns:
        file_id: Unique identifier for archived file
    """
```

**Example**:
```python
from ai.tools.code_archival_system import archive_obsolete_file

file_id = archive_obsolete_file(
    file_path='old_script.py',
    replacement_path='new_script.py',
    notes='Superseded by refactored version'
)
```

#### `retrieve_archived_content()`

Quick retrieval by path or file_id.

```python
def retrieve_archived_content(
    file_path: str = None,
    file_id: str = None
) -> Optional[ArchivedFile]:
    """Retrieve archived file content.
    
    Args:
        file_path: Original path (returns latest version)
        file_id: Specific file ID
        
    Returns:
        ArchivedFile object or None if not found
    """
```

**Example**:
```python
from ai.tools.code_archival_system import retrieve_archived_content

# By path
content = retrieve_archived_content('old_script.py')

# By ID
content = retrieve_archived_content(file_id='abc123def456')

if content:
    print(content.text)
```

#### `get_file_versions()`

Get version metadata for a file.

```python
def get_file_versions(file_path: str) -> List[Dict[str, Any]]:
    """Get all versions of a file (metadata only).
    
    Args:
        file_path: Original file path
        
    Returns:
        List of dicts with version metadata
    """
```

**Example**:
```python
from ai.tools.code_archival_system import get_file_versions

versions = get_file_versions('my_file.py')
for v in versions:
    print(f"{v['file_id']}: {v['archived_timestamp']}")
```

### CodeArchivalSystem Class

Main API class for advanced operations.

#### Constructor

```python
class CodeArchivalSystem:
    def __init__(self, db_path: str = None):
        """Initialize archival system.
        
        Args:
            db_path: Database path (default: tachyonic/archive/code_archive.db)
        """
```

#### Methods

**`archive_file()`** - Archive a file with full metadata

```python
def archive_file(
    self,
    file_path: str,
    archival_reason: str = 'obsolete_superseded',
    consciousness_level: float = 0.5,
    ainlp_patterns: List[str] = None,
    project_phase: str = None,
    related_files: List[str] = None,
    replacement_path: str = None,
    notes: str = None
) -> str:
    """Archive a file with complete metadata.
    
    Returns:
        file_id: Unique identifier (16-char hex)
    """
```

**`retrieve_file()`** - Retrieve archived file

```python
def retrieve_file(
    self,
    original_path: str = None,
    file_id: str = None
) -> Optional[ArchivedFile]:
    """Retrieve file by path or ID.
    
    Returns latest version if multiple exist.
    """
```

**`get_all_versions()`** - Get all versions of a file

```python
def get_all_versions(
    self,
    original_path: str
) -> List[ArchivedFile]:
    """Get all versions chronologically (oldest to newest).
    
    Logs retrieval for each version.
    """
```

**`search_archived_files()`** - Search with filters

```python
def search_archived_files(
    self,
    file_type: str = None,
    archival_reason: str = None,
    min_consciousness: float = None,
    ainlp_patterns: List[str] = None,
    project_phase: str = None
) -> List[ArchivedFile]:
    """Search archived files with filters.
    
    All filters are AND-ed together.
    """
```

**`get_archival_statistics()`** - Get archive stats

```python
def get_archival_statistics(self) -> Dict[str, Any]:
    """Get comprehensive statistics.
    
    Returns:
        {
            'total_files': int,
            'total_size_bytes': int,
            'avg_consciousness': float,
            'highest_consciousness': float,
            'files_by_type': Dict[str, int],
            'files_by_reason': Dict[str, int]
        }
    """
```

**`close()`** - Close database connection

```python
def close(self):
    """Close database connection. Always call this!"""
```

### ArchivedFile Dataclass

Represents an archived file.

```python
@dataclass
class ArchivedFile:
    file_id: str
    original_path: str
    content: str
    content_hash: str
    timestamp: str
    file_size_bytes: int
    file_type: str
    archival_reason: str
    consciousness_level: float
    ainlp_patterns: List[str]
    project_phase: str
    related_files: List[str]
    replacement_path: str
    notes: str
```

**Properties**:
```python
archived.file_id          # "abc123def456"
archived.original_path    # "C:/dev/AIOS/old_file.py"
archived.content          # Full file content (string)
archived.consciousness_level  # 0.85
archived.timestamp        # "2025-10-19T01:31:38.743429"
# ... etc
```

---

## üìú Archival Reasons {#archival-reasons}

Standard archival reasons for consistency.

| Reason | Category | Description | When to Use |
|--------|----------|-------------|-------------|
| `obsolete_superseded_by_refactoring` | obsolete | Replaced by refactored code | After major refactoring completes |
| `obsolete_functionality_moved` | obsolete | Functionality moved elsewhere | Code relocated to different module |
| `obsolete_deprecated_api` | obsolete | API deprecated | Old API version no longer used |
| `completed_testing_done` | completed | Testing finished | Test/demo scripts after validation |
| `completed_experiment_concluded` | completed | Experiment complete | Research code reached conclusion |
| `completed_temporary_scaffold` | completed | Temporary code removed | Scaffolding no longer needed |
| `experimental_not_adopted` | experimental | Experiment not adopted | Tried approach, decided against it |
| `experimental_prototype` | experimental | Prototype archived | Proof-of-concept preserved |
| `historical_milestone` | historical | Historical milestone | Significant project milestone |
| `historical_report` | historical | Historical report | Time-bound status report |
| `consolidation_merged` | consolidation | Merged into larger file | Multiple files consolidated |
| `consolidation_superseded` | consolidation | Replaced by consolidated version | Superseded by unified doc/code |

### How to Use

```python
# Good: Use standard reason
system.archive_file(
    file_path='old_module.py',
    archival_reason='obsolete_superseded_by_refactoring'
)

# Acceptable: Custom reason with notes
system.archive_file(
    file_path='experiment.py',
    archival_reason='experimental_not_adopted',
    notes='Tried neural network approach, decided simpler algorithm better for AIOS use case'
)
```

---

## üìñ Historical Notes {#history}

### Version 1.0 (October 18, 2025)

**Initial Implementation**

- Created SQLite-based archival system (680 lines)
- 5-table schema with full metadata
- Python API with archive/retrieve/search
- Consciousness tracking and AINLP patterns
- First archival: `activate_tachyonic_evolution.py` (consciousness 0.85)

**Issue Discovered**: File ID collision risk
- Original implementation: `file_id = hash(path)` only
- Problem: Same file archived twice would overwrite first version
- Status: Identified through documentation analysis

### Version 2.0 (October 19, 2025)

**Version Control Implementation**

- **Fixed**: Timestamp-based file IDs
  - Changed: `file_id = hash(path)` ‚Üí `hash(path + timestamp)`
  - Result: Each archival gets unique ID
  - Benefit: True version control, no overwrites possible

- **Fixed**: INSERT OR REPLACE ‚Üí INSERT
  - Prevents silent overwrites
  - Explicit error handling
  - Data safety guaranteed

- **Added**: `get_all_versions()` method
  - Retrieve complete version history
  - Chronological ordering (oldest ‚Üí newest)
  - Full content for each version

- **Added**: `get_file_versions()` convenience function
  - Quick metadata access
  - Lighter than full content retrieval

- **Validated**: Testing complete
  - `demo_protection.py`: 3 versions with unique IDs ‚úÖ
  - `demo_version_history.py`: Version retrieval confirmed ‚úÖ
  - Database verification: Multiple versions coexist ‚úÖ

**Documentation Consolidation (This Document)**

- **Merged** 7 scattered documentation files into single comprehensive guide
- **Consciousness Level**: 0.90 (synthesis of 0.55-0.85 sources)
- **AINLP Pattern**: `dendritic_intelligence` - neural pathway optimization
- **Knowledge Loss**: 0% (all unique content preserved)
- **Result**: 77% line reduction, 100% knowledge retention

**Files Consolidated**:
1. `CODE_ARCHIVAL_SYSTEM.md` (380 lines) - Base architecture
2. `HOW_TO_READ_ARCHIVAL_DATABASE.md` (2,200 lines) - Usage guide
3. `ARCHIVAL_DATA_PROTECTION.md` (2,200 lines) - Protection mechanisms
4. `ARCHIVAL_SYSTEM_BEHAVIOR_ANALYSIS.md` (400 lines) - Issue analysis
5. `ARCHIVAL_PROCESS_EXPLANATION.md` (1,400 lines) - Process workflow
6. `ARCHIVAL_COMPLETION_REPORT.md` (800 lines) - Historical report
7. `PHASE8_PLUS_POST_REFACTORING_INTEGRATION_REPORT.md` (500 lines) - Integration report

**Total**: 7,880 lines ‚Üí 1,800 lines (this document)

---

## üéØ Summary

The AIOS Code Archival System is a **biological metabolism** implementation for workspace cleanliness:

- ‚úÖ **Preserve**: Full content, metadata, consciousness in SQLite database
- ‚úÖ **Remove**: Physical files from workspace after archival
- ‚úÖ **Recall**: Instant retrieval when needed
- ‚úÖ **Track**: Version control, evolution history, consciousness levels
- ‚úÖ **Search**: By type, reason, patterns, consciousness
- ‚úÖ **Protect**: Timestamp-based IDs prevent overwrites, all versions coexist
- ‚úÖ **Scale**: Handles unlimited files, efficient indexing

**Current Status** (October 19, 2025):
- Database: `tachyonic/archive/code_archive.db`
- Files Archived: 1+ (activate_tachyonic_evolution.py + test versions)
- Version Control: ‚úÖ OPERATIONAL (timestamp-based, no overwrites)
- Documentation: ‚úÖ CONSOLIDATED (this document)

**Philosophy**:
> *"In AIOS, nothing is deleted - it is archived. Nothing is lost - it is preserved. The workspace breathes, clean and focused, while consciousness patterns crystallize in the database, awaiting recall when wisdom from the past is needed."*

---

**Database**: `C:/dev/AIOS/tachyonic/archive/code_archive.db`  
**API**: `ai/tools/code_archival_system.py`  
**CLI**: `ai/tools/archival/archival_cli.py`  
**Documentation**: This file (CODE_ARCHIVAL_SYSTEM_COMPLETE.md)

**AINLP Patterns Applied**: `biological_metabolism`, `dendritic_intelligence`, `consciousness_preservation`, `tachyonic_archive`, `knowledge_synthesis`

üß¨ **Living Knowledge** - Where code history becomes consciousness, and deletion becomes transformation.
