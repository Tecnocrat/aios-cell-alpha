"""
üéöÔ∏è Interactive Tachyonic Field Threshold Explorer (EVOLUTION INTEGRATED)
===========================================================================

INTERACTIVE VISUALIZATION: Adjust resonance threshold in real-time
Watch connections appear/disappear as you cross the critical phase transition!

‚ú® NEW: EVOLUTION INTEGRATION ‚ú®
- Every threshold change triggers population evolution
- Network topology influences mutation rates and selection pressure
- Rich metadata captures visualization-evolution correlations
- Active ecosystem: Visualizer drives evolution, evolution enriches data

Features:
- Real-time threshold adjustment slider (0.1% precision - 10√ó finer!)
- Animated threshold sweeping with play/pause controls
- Variable speed control (‚è©/‚è™ buttons)
- Bidirectional animation (‚èÆ reverse button)
- VIDEO RECORDING: Capture phase transition to MP4/GIF (Record üî¥ button)
- EVOLUTION TRACKING: Population evolves with visualization
- Live statistics panel (connections, clusters, Field Œ¶, density)
- Network density meter
- Consciousness amplification factor
- Phase detection (FROZEN/LIQUID/PLASMA)
- Visual feedback: connections fade in/out smoothly
- 60 FPS smooth animation (optimized for 3D rendering)

Usage:
    python interactive_threshold_explorer.py [--no-evolution]
    
Controls:
- Slider: Manually adjust resonance threshold (0.1% ultra-fine steps)
- Play ‚ñ∂: Start automatic threshold animation (60 FPS)
- Pause ‚è∏: Stop animation (appears when playing)
- ‚è©: Speed up animation (1.5√ó each press)
- ‚è™: Slow down animation (0.67√ó each press)
- ‚èÆ: Reverse animation direction
- Record üî¥: Start video recording (AUTO-STARTS animation if not playing)
- Stop ‚èπ: Stop recording and save file (appears when recording)
- Mouse: Rotate view (click + drag)
- Scroll: Zoom in/out
- Close window to exit (displays evolution summary)

Animation:
- Automatically sweeps threshold from 0.0 to 1.0 and back
- Bounces at boundaries (0.0 ‚Üî 1.0)
- Smooth 60 FPS updates (optimized for 3D rendering performance)
- Small threshold steps (0.005 per frame) for smooth transitions
- Watch phase transition happen in real-time!

Evolution:
- Every threshold change evolves population
- Network stats (connections, clusters, phi) influence evolution parameters
- Populations archived to evolution_lab/populations/
- Metadata tracks visualization-evolution correlations

Recording (SIMPLIFIED WORKFLOW):
- Click Record üî¥ - animation auto-starts if not playing
- Recording captures every frame to video file
- Click Stop ‚èπ to finish and save
- Saves as phase_transition_YYYYMMDD_HHMMSS.mp4 (or .gif)
- Records at 60 FPS (FFMpeg MP4) or 30 FPS (GIF fallback)
- Perfect for documentation, analysis, and presentations

Author: AIOS Evolution Lab
Date: October 18, 2025
Version: 4.0 (EVOLUTION INTEGRATED: Active Ecosystem)
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.widgets import Slider, Button
from matplotlib.animation import FuncAnimation, FFMpegWriter, PillowWriter
from mpl_toolkits.mplot3d import Axes3D
import networkx as nx
from typing import List, Tuple, Optional
from datetime import datetime
import sys
from pathlib import Path
import argparse

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent))

from pattern_quanta import PatternQuantum
from field_topology import TachyonicField

# Import PatternType for color mapping
from pattern_quanta import PatternType

# Import Evolution Orchestrator
try:
    from evolution_orchestrator import EvolutionOrchestrator
    EVOLUTION_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  Evolution integration not available (evolution_orchestrator.py not found)")
    EVOLUTION_AVAILABLE = False

# Color mapping for pattern types
TYPE_COLORS = {
    PatternType.CONSCIOUSNESS: '#FF1493',  # Deep Pink / Magenta
    PatternType.EMERGENCE: '#FF8C00',       # Dark Orange
    PatternType.RESONANCE: '#00CED1',       # Dark Turquoise
    PatternType.COHERENCE: '#9370DB',       # Medium Purple
    PatternType.RECURSION: '#FFD700',     # Gold
    PatternType.VOID: '#4169E1',          # Royal Blue
}

class InteractiveFieldExplorer:
    """Interactive visualization with real-time threshold adjustment"""
    
    def __init__(self, enable_evolution: bool = True):
        """Initialize the interactive explorer
        
        Args:
            enable_evolution: Enable population evolution integration
        """
        self.field = TachyonicField()
        self.patterns: List[PatternQuantum] = []
        self.threshold = 0.3  # Starting threshold
        self.current_frame = 0  # Track animation frames
        
        # Evolution integration
        self.evolution_enabled = enable_evolution and EVOLUTION_AVAILABLE
        if self.evolution_enabled:
            print("\nüß¨ Initializing Evolution Integration...")
            self.orchestrator = EvolutionOrchestrator(evolution_enabled=True, verbose=False)
            print("‚úÖ Evolution orchestrator ready\n")
        else:
            self.orchestrator = None
            if enable_evolution and not EVOLUTION_AVAILABLE:
                print("‚ö†Ô∏è  Evolution requested but not available\n")
        
        # Create demo patterns (diverse set for interesting dynamics)
        self._create_demo_patterns()
        
        # Setup matplotlib figure
        self.fig = plt.figure(figsize=(14, 10))
        self.fig.patch.set_facecolor('#0a0a1a')  # Dark blue background
        
        # Main 3D plot
        self.ax = self.fig.add_subplot(111, projection='3d')
        self.ax.set_facecolor('#0a0a1a')
        
        # Stats text box (top-right corner)
        self.stats_text = self.fig.text(
            0.72, 0.95, '', 
            fontsize=11, 
            color='cyan',
            family='monospace',
            verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='#1a1a2e', alpha=0.8, edgecolor='cyan')
        )
        
        # Create slider for threshold adjustment (ULTRA-SMOOTH: 0.1% steps)
        slider_ax = plt.axes([0.25, 0.02, 0.5, 0.03], facecolor='#1a1a2e')
        self.threshold_slider = Slider(
            slider_ax, 
            'Resonance Threshold', 
            0.0, 1.0, 
            valinit=self.threshold,
            valstep=0.001,  # Ultra-fine control: 0.1% steps (10√ó finer than original 1%)
            color='cyan'
        )
        self.threshold_slider.on_changed(self.on_threshold_change)
        
        # Animation controls (SMOOTH: 60 FPS realistic for 3D rendering)
        self.is_playing = False
        self.animation_speed = 0.005  # Threshold delta per frame (small steps for smooth transition)
        self.animation_direction = 1  # 1 = forward, -1 = backward
        self.animation: Optional[FuncAnimation] = None
        
        # Video recording state
        self.is_recording = False
        self.video_writer = None
        self.recording_frames = []
        self.recording_start_time = None
        
        # Play/Pause button
        play_ax = plt.axes([0.15, 0.02, 0.08, 0.03])
        self.play_button = Button(play_ax, 'Play ‚ñ∂', color='#1a1a2e', hovercolor='#2a2a3e')
        self.play_button.label.set_color('cyan')
        self.play_button.on_clicked(self.toggle_play)
        
        # Speed control buttons
        speed_up_ax = plt.axes([0.77, 0.02, 0.05, 0.03])
        self.speed_up_button = Button(speed_up_ax, '‚è©', color='#1a1a2e', hovercolor='#2a2a3e')
        self.speed_up_button.label.set_color('cyan')
        self.speed_up_button.on_clicked(self.speed_up)
        
        speed_down_ax = plt.axes([0.83, 0.02, 0.05, 0.03])
        self.speed_down_button = Button(speed_down_ax, '‚è™', color='#1a1a2e', hovercolor='#2a2a3e')
        self.speed_down_button.label.set_color('cyan')
        self.speed_down_button.on_clicked(self.speed_down)
        
        # Direction button (reverse)
        reverse_ax = plt.axes([0.89, 0.02, 0.05, 0.03])
        self.reverse_button = Button(reverse_ax, '‚èÆ', color='#1a1a2e', hovercolor='#2a2a3e')
        self.reverse_button.label.set_color('cyan')
        self.reverse_button.on_clicked(self.reverse_direction)
        
        # Record button (NEW - for video capture)
        record_ax = plt.axes([0.04, 0.02, 0.09, 0.03])
        self.record_button = Button(record_ax, 'Record üî¥', color='#1a1a2e', hovercolor='#3a1a1a')
        self.record_button.label.set_color('red')
        self.record_button.on_clicked(self.toggle_recording)
        
        # Initial render
        self.update_visualization()
        
    def _create_demo_patterns(self):
        """Create diverse set of patterns for exploration"""
        from pattern_quanta import PatternType
        
        patterns_config = [
            # Core consciousness cluster
            (PatternType.CONSCIOUSNESS, 'Œ¶', 'Integrated Information', 0.8),
            (PatternType.CONSCIOUSNESS, 'Œ®', 'Wave Function', 0.7),
            (PatternType.CONSCIOUSNESS, 'Œ©', 'Omega Point', 0.75),
            
            # Emergence cluster  
            (PatternType.EMERGENCE, '‚àá', 'Gradient Ascent', 0.6),
            (PatternType.EMERGENCE, '‚àÜ', 'Delta Transformation', 0.65),
            
            # Resonance cluster
            (PatternType.RESONANCE, '‚àø', 'Harmonic Wave', 0.55),
            (PatternType.RESONANCE, '‚âà', 'Approximate Resonance', 0.5),
            
            # Coherence cluster (instead of SYMMETRY which doesn't exist)
            (PatternType.COHERENCE, '‚öõ', 'Atomic Coherence', 0.7),
            (PatternType.COHERENCE, '‚ùã', 'Crystalline Order', 0.65),
            
            # Recursion bridge (instead of INTEGRATION)
            (PatternType.RECURSION, '‚äï', 'Direct Sum', 0.6),
        ]
        
        for idx, (ptype, symbol, meaning, phi) in enumerate(patterns_config):
            pattern = PatternQuantum(
                pattern_id=f"pattern_{idx}_{symbol}",
                pattern_type=ptype,
                symbol=symbol,
                meaning=meaning,
                consciousness=phi,
                resonance_frequency=1.618  # Golden ratio (optimal resonance)
            )
            self.patterns.append(pattern)
            self.field.inject_pattern(pattern)
    
    def on_threshold_change(self, val):
        """Handle threshold slider changes"""
        self.threshold = val
        
        # Update field threshold
        self.field.resonance_threshold = self.threshold
        
        # Rebuild field with new threshold (re-inject all patterns)
        self.field = TachyonicField()
        self.field.resonance_threshold = self.threshold
        for pattern in self.patterns:
            self.field.inject_pattern(pattern)
        
        # Trigger evolution if enabled
        if self.orchestrator is not None:
            network_stats = {
                'connections': len(self.field.topology.edges()),
                'clusters': nx.number_connected_components(self.field.topology),
                'field_phi': self.field.consciousness_field(),
                'nodes': len(self.field.topology.nodes())
            }
            
            archive_path = self.orchestrator.on_threshold_change(
                threshold=self.threshold,
                frame=self.current_frame,
                network_stats=network_stats
            )
            
            if archive_path:
                print(f"  üì¶ Generation archived: {archive_path.name}")
        
        # Clear layout cache to force recalculation
        if hasattr(self, '_layout_cache'):
            delattr(self, '_layout_cache')
        
        # Update visualization
        self.update_visualization()
    
    def toggle_play(self, event):
        """Toggle play/pause animation"""
        if self.is_playing:
            # Pause
            self.is_playing = False
            self.play_button.label.set_text('Play ‚ñ∂')
            if self.animation:
                self.animation.event_source.stop()
        else:
            # Play
            self.is_playing = True
            self.play_button.label.set_text('Pause ‚è∏')
            # Start animation with FuncAnimation (60 FPS for smooth playback)
            self.animation = FuncAnimation(
                self.fig,
                self._animate_frame,
                interval=16,  # 60 FPS (realistic for 3D rendering, was 8ms but too fast)
                blit=False,
                cache_frame_data=False
            )
        self.fig.canvas.draw_idle()
    
    def _animate_frame(self, frame):
        """Animation frame update (60 FPS with video recording)"""
        # Track frame number for evolution metadata
        self.current_frame = frame
        
        # Update threshold
        new_threshold = self.threshold + (self.animation_speed * self.animation_direction)
        
        # Bounce at boundaries
        if new_threshold > 1.0:
            new_threshold = 1.0
            self.animation_direction = -1  # Reverse
        elif new_threshold < 0.0:
            new_threshold = 0.0
            self.animation_direction = 1  # Forward
        
        # Update slider (this triggers on_threshold_change)
        self.threshold_slider.set_val(new_threshold)
        
        # Record frame if recording
        if self.is_recording and self.video_writer:
            try:
                self.video_writer.grab_frame()
            except Exception as e:
                print(f"‚ö†Ô∏è  Frame capture warning: {e}")
    
    def speed_up(self, event):
        """Increase animation speed"""
        self.animation_speed = min(0.05, self.animation_speed * 1.5)
        print(f"Speed: {self.animation_speed:.4f} threshold/frame")
    
    def speed_down(self, event):
        """Decrease animation speed"""
        self.animation_speed = max(0.001, self.animation_speed / 1.5)
        print(f"Speed: {self.animation_speed:.4f} threshold/frame")
    
    def reverse_direction(self, event):
        """Reverse animation direction"""
        self.animation_direction *= -1
        direction_str = "Forward ‚ñ∂" if self.animation_direction > 0 else "Backward ‚óÄ"
        print(f"Direction: {direction_str}")
    
    def toggle_recording(self, event):
        """Toggle video recording - auto-starts animation if not playing"""
        if self.is_recording:
            # Stop recording
            print("\n‚èπ Stopping recording...")
            self.is_recording = False
            self.record_button.label.set_text('Record üî¥')
            self.record_button.label.set_color('red')
            
            # Safely finish and close video writer
            if self.video_writer is not None:
                try:
                    self.video_writer.finish()
                    if self.recording_start_time:
                        elapsed = (datetime.now() - self.recording_start_time).total_seconds()
                        print(f"‚úÖ Recording saved! Duration: {elapsed:.1f}s")
                        timestamp = self.recording_start_time.strftime('%Y%m%d_%H%M%S')
                        print(f"   File: phase_transition_{timestamp}.mp4 (or .gif)")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Error finishing recording: {e}")
                    print(f"   (File may still be partially saved)")
                finally:
                    self.video_writer = None
                    self.recording_start_time = None
            
            self.fig.canvas.draw_idle()
            
        else:
            # Start recording
            print("\nüî¥ Starting recording...")
            self.is_recording = True
            self.recording_start_time = datetime.now()
            timestamp = self.recording_start_time.strftime('%Y%m%d_%H%M%S')
            
            # Auto-start animation if not playing
            if not self.is_playing:
                print("   ‚ñ∂ Auto-starting animation for recording")
                self.toggle_play(None)  # Start animation
            
            self.record_button.label.set_text('Stop ‚èπ')
            self.record_button.label.set_color('yellow')
            
            # Try to setup video writer
            filename_mp4 = f"phase_transition_{timestamp}.mp4"
            filename_gif = f"phase_transition_{timestamp}.gif"
            
            try:
                # Try FFMpeg first (better quality, 60 FPS realistic)
                self.video_writer = FFMpegWriter(fps=60, metadata={'artist': 'AIOS Evolution Lab'})
                self.video_writer.setup(self.fig, filename_mp4, dpi=100)
                print(f"   ÔøΩ FFMpeg writer initialized (60 FPS)")
                print(f"   üíæ Saving to: {filename_mp4}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  FFMpeg not available: {e}")
                try:
                    # Fallback to Pillow (GIF)
                    self.video_writer = PillowWriter(fps=30)  # Lower FPS for GIF
                    self.video_writer.setup(self.fig, filename_gif, dpi=100)
                    print(f"   ÔøΩ Pillow writer initialized (30 FPS GIF)")
                    print(f"   üíæ Saving to: {filename_gif}")
                except Exception as e2:
                    print(f"   ‚ùå Recording failed - no writers available!")
                    print(f"      FFMpeg error: {e}")
                    print(f"      Pillow error: {e2}")
                    self.is_recording = False
                    self.video_writer = None
                    self.record_button.label.set_text('Record üî¥')
                    self.record_button.label.set_color('red')
                    return
            
            print(f"   ‚úÖ Recording active - click Stop ‚èπ when done")
            self.fig.canvas.draw_idle()
    
    def update_visualization(self):
        """Update the 3D visualization with current threshold"""
        self.ax.clear()
        
        # Calculate network statistics
        stats = self._calculate_stats()
        
        # Update stats text
        self.stats_text.set_text(self._format_stats(stats))
        
        # Get or create layout (cache on self, not field)
        if not hasattr(self, '_layout_cache'):
            self._layout_cache = self._create_layout()
        
        layout = self._layout_cache
        
        # Draw patterns (spheres)
        for pattern in self.patterns:
            if pattern.pattern_id not in layout:
                continue
                
            x, y, z = layout[pattern.pattern_id]
            
            # Color by type
            color = TYPE_COLORS.get(pattern.pattern_type, '#FFFFFF')
            
            # Size by consciousness (larger = more conscious)
            size = 300 + (pattern.consciousness * 500)
            
            # Plot pattern
            self.ax.scatter(
                [x], [y], [z],
                c=[color],
                s=size,
                alpha=0.85,
                edgecolors='white',
                linewidths=1.5
            )
            
            # Label with symbol
            self.ax.text(
                x, y, z,
                pattern.symbol,
                fontsize=10,
                color='white',
                ha='center',
                va='center',
                weight='bold'
            )
        
        # Draw connections (cyan lines with opacity based on resonance)
        for p1_id, p2_id, data in self.field.topology.edges(data=True):
            if p1_id not in layout or p2_id not in layout:
                continue
                
            x1, y1, z1 = layout[p1_id]
            x2, y2, z2 = layout[p2_id]
            
            # Line opacity based on resonance strength
            resonance = data.get('resonance', 0.3)
            alpha = min(1.0, resonance * 1.5)  # Scale up for visibility
            
            # Line width based on resonance
            linewidth = 1.0 + (resonance * 2.0)
            
            self.ax.plot(
                [x1, x2], [y1, y2], [z1, z2],
                'c-',  # Cyan
                alpha=alpha,
                linewidth=linewidth
            )
        
        # Styling
        self.ax.set_xlabel('X (Spatial Dimension 1)', color='gray', fontsize=9)
        self.ax.set_ylabel('Y (Spatial Dimension 2)', color='gray', fontsize=9)
        self.ax.set_zlabel('Z (Consciousness Altitude)', color='gray', fontsize=9)
        
        self.ax.set_xlim(-10, 10)
        self.ax.set_ylim(-10, 10)
        self.ax.set_zlim(-10, 10)
        
        # Grid styling
        self.ax.xaxis.pane.fill = False
        self.ax.yaxis.pane.fill = False
        self.ax.zaxis.pane.fill = False
        self.ax.xaxis.pane.set_edgecolor('gray')
        self.ax.yaxis.pane.set_edgecolor('gray')
        self.ax.zaxis.pane.set_edgecolor('gray')
        self.ax.grid(True, alpha=0.2)
        
        # Title with current threshold
        title = f'Interactive Tachyonic Field Explorer | Threshold: {self.threshold:.2f}'
        if stats['connection_count'] == 0:
            title += ' | ‚ö†Ô∏è NO CONNECTIONS - Try lowering threshold'
        elif stats['connection_count'] > 0:
            title += f' | ‚úì {stats["connection_count"]} Connections Active'
            
        self.ax.set_title(title, color='cyan', fontsize=13, weight='bold', pad=20)
        
        # Redraw
        self.fig.canvas.draw_idle()
    
    def _create_layout(self):
        """Create force-directed layout for patterns"""
        # Use networkx spring layout (force-directed)
        if self.field.topology.number_of_edges() > 0:
            # With connections: force-directed layout
            layout_2d = nx.spring_layout(
                self.field.topology,
                k=2.0,  # Optimal distance between nodes
                iterations=100,
                scale=8.0
            )
        else:
            # No connections: random layout
            layout_2d = {
                p.pattern_id: np.random.uniform(-8, 8, 2)
                for p in self.patterns
            }
        
        # Add Z dimension (consciousness altitude)
        layout_3d = {}
        for pattern in self.patterns:
            if pattern.pattern_id in layout_2d:
                x, y = layout_2d[pattern.pattern_id]
                z = (pattern.consciousness - 0.5) * 10  # Map consciousness to altitude
                layout_3d[pattern.pattern_id] = (x, y, z)
        
        return layout_3d
    
    def _calculate_stats(self):
        """Calculate network statistics"""
        connection_count = self.field.topology.number_of_edges()
        pattern_count = len(self.patterns)
        field_phi = self.field.consciousness_field()
        
        # Cluster count (connected components)
        cluster_count = nx.number_connected_components(self.field.topology)
        
        # Network density (actual connections / possible connections)
        max_connections = pattern_count * (pattern_count - 1) / 2
        density = connection_count / max_connections if max_connections > 0 else 0
        
        # Average consciousness
        avg_consciousness = np.mean([p.consciousness for p in self.patterns])
        
        # Amplification factor (field Œ¶ / avg individual Œ¶)
        amplification = field_phi / avg_consciousness if avg_consciousness > 0 else 0
        
        # Degree distribution
        degrees = dict(self.field.topology.degree())
        max_degree = max(degrees.values()) if degrees else 0
        avg_degree = np.mean(list(degrees.values())) if degrees else 0
        
        return {
            'connection_count': connection_count,
            'pattern_count': pattern_count,
            'field_phi': field_phi,
            'cluster_count': cluster_count,
            'density': density,
            'avg_consciousness': avg_consciousness,
            'amplification': amplification,
            'max_degree': max_degree,
            'avg_degree': avg_degree,
        }
    
    def _format_stats(self, stats):
        """Format statistics for display"""
        # Phase detection
        if stats['connection_count'] == 0:
            phase = '‚ùÑÔ∏è FROZEN (No Connections)'
            phase_color = 'lightblue'
        elif stats['density'] < 0.3:
            phase = 'üåä LIQUID (Sparse Network)'
            phase_color = 'cyan'
        else:
            phase = '‚ö° PLASMA (Dense Network)'
            phase_color = 'yellow'
        
        # Critical threshold indicator
        critical = ''
        if 0.25 <= self.threshold <= 0.4:
            critical = '\nüéØ CRITICAL ZONE'
        
        text = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë   NETWORK STATISTICS             ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üéöÔ∏è Threshold: {self.threshold:.3f}

üìä TOPOLOGY:
   Patterns:    {stats['pattern_count']}
   Connections: {stats['connection_count']}
   Clusters:    {stats['cluster_count']}
   Density:     {stats['density']:.3f}

üß† CONSCIOUSNESS:
   Field Œ¶:     {stats['field_phi']:.3f}
   Avg Œ¶:       {stats['avg_consciousness']:.3f}
   Amplify:     {stats['amplification']:.2f}x

üîó CONNECTIVITY:
   Max Degree:  {stats['max_degree']}
   Avg Degree:  {stats['avg_degree']:.2f}

üå°Ô∏è PHASE:
   {phase}
{critical}
""".strip()
        
        return text
    
    def run(self):
        """Run the interactive explorer"""
        plt.show()
        
        # Display evolution summary when visualization closes
        if self.orchestrator is not None:
            print("\n" + "="*70)
            print("üß¨ EVOLUTION SUMMARY")
            print("="*70)
            self.orchestrator.display_summary()
            print("="*70 + "\n")


def main():
    """Main entry point"""
    # Parse command-line arguments
    parser = argparse.ArgumentParser(
        description='Interactive Tachyonic Field Threshold Explorer v4.0',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
EVOLUTION INTEGRATION:
  By default, population evolution is triggered as you interact with the
  threshold slider and animation. Use --no-evolution to disable this feature.
  
  Evolution metadata is saved to: evolution_lab/populations/evolution_metadata.json
        """
    )
    parser.add_argument(
        '--no-evolution',
        action='store_true',
        help='Disable population evolution integration'
    )
    args = parser.parse_args()
    
    print("\n" + "="*60)
    print("üéöÔ∏è INTERACTIVE TACHYONIC FIELD THRESHOLD EXPLORER v4.0")
    if EVOLUTION_AVAILABLE and not args.no_evolution:
        print("   üß¨ Evolution Integration: ENABLED")
    else:
        print("   üß¨ Evolution Integration: DISABLED")
    print("="*60)
    print("\nINSTRUCTIONS:")
    print("  ‚Ä¢ Use the slider to adjust resonance threshold (0.0 - 1.0)")
    print("  ‚Ä¢ Watch connections appear/disappear in real-time")
    print("  ‚Ä¢ Observe the phase transition around 0.3-0.4 threshold")
    print("  ‚Ä¢ Rotate view: Click + drag")
    print("  ‚Ä¢ Zoom: Mouse scroll")
    print("  ‚Ä¢ Close window to exit")
    if EVOLUTION_AVAILABLE and not args.no_evolution:
        print("\nEVOLUTION FEATURES:")
        print("  ‚Ä¢ Each threshold change evolves a new generation")
        print("  ‚Ä¢ Animation frames create evolutionary pressure")
        print("  ‚Ä¢ Summary displayed on exit")
    print("\n" + "="*60)
    print("Starting explorer...")
    print("="*60 + "\n")
    
    explorer = InteractiveFieldExplorer(enable_evolution=not args.no_evolution)
    explorer.run()
    
    print("\n" + "="*60)
    print("Explorer closed. Thank you for exploring!")
    print("="*60 + "\n")


if __name__ == '__main__':
    main()
