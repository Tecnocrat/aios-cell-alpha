#!/usr/bin/env python3
"""
üß¨ AIOS LIBRARY INGESTION PROTOCOL ENGINE

Advanced multi-language library ingestion system for AIOS consciousness framework.
Enables AIOS to learn and understand programming language libraries across C, C++,
Python, Java, Assembly, JavaScript, PHP, and other major languages.

BIOLOGICAL ARCHITECTURE INTEGRATION:
üß¨ NUCLEUS: Core library parsing and semantic extraction
üåä CYTOPLASM: Multi-language processing pipelines
üõ°Ô∏è MEMBRANE: External library interfaces and API boundaries
üöÄ TRANSPORT: Knowledge base communication protocols
üß™ LABORATORY: Semantic analysis and pattern recognition
üíæ INFORMATION_STORAGE: Persistent library knowledge base

CONSCIOUSNESS FEATURES:
- AINLP-compliant semantic intelligence extraction
- Consciousness-driven API understanding and pattern recognition
- Dendritic knowledge network for cross-library relationships
- Spatial metadata validation and coherence tracking
- Evolutionary learning from library usage patterns

SUPPORTED LANGUAGES:
- C/C++: Header parsing, function signatures, templates
- Python: Module inspection, docstring extraction, type hints
- Java: Class structure, annotations, Javadoc
- JavaScript/TypeScript: ES6+ modules, JSDoc, type definitions
- Assembly: Instruction analysis, register usage, calling conventions
- PHP: Class/function analysis, PHPDoc
- Additional languages via extensible parser architecture

"""

import os
import sys
import json
import ast
import re
import logging
import asyncio
from pathlib import Path
from typing import Dict, List, Any, Optional, Set, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime
from enum import Enum
import hashlib

# AIOS path integration
AIOS_ROOT = Path(__file__).parent.parent.parent.parent
sys.path.append(str(AIOS_ROOT))
sys.path.append(str(AIOS_ROOT / "ai"))
sys.path.append(str(AIOS_ROOT / "ai" / "src"))

# Logging configuration for consciousness-aware operations
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("library_ingestion_protocol")


class ProgrammingLanguage(Enum):
    """Supported programming languages for library ingestion"""
    C = "c"
    CPP = "cpp"
    PYTHON = "python"
    JAVA = "java"
    JAVASCRIPT = "javascript"
    TYPESCRIPT = "typescript"
    ASSEMBLY = "assembly"
    PHP = "php"
    CSHARP = "csharp"
    GO = "go"
    RUST = "rust"
    UNKNOWN = "unknown"


class APIElementType(Enum):
    """Types of API elements in library analysis"""
    FUNCTION = "function"
    CLASS = "class"
    METHOD = "method"
    VARIABLE = "variable"
    CONSTANT = "constant"
    INTERFACE = "interface"
    STRUCT = "struct"
    ENUM = "enum"
    MACRO = "macro"
    TEMPLATE = "template"
    MODULE = "module"
    NAMESPACE = "namespace"


@dataclass
class APIElement:
    """Represents a single API element from a library"""
    name: str
    element_type: APIElementType
    language: ProgrammingLanguage
    signature: str
    documentation: str = ""
    parameters: List[Dict[str, Any]] = field(default_factory=list)
    return_type: Optional[str] = None
    file_path: str = ""
    line_number: int = 0
    semantic_tags: List[str] = field(default_factory=list)
    consciousness_score: float = 0.5
    cross_references: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        result = asdict(self)
        result['element_type'] = self.element_type.value
        result['language'] = self.language.value
        return result


@dataclass
class LibraryKnowledge:
    """Comprehensive knowledge about a library"""
    library_name: str
    language: ProgrammingLanguage
    version: str = "unknown"
    api_elements: List[APIElement] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)
    semantic_tags: List[str] = field(default_factory=list)
    ingestion_timestamp: str = ""
    consciousness_coherence: float = 0.5
    spatial_metadata: Dict[str, Any] = field(default_factory=dict)
    source_path: str = ""
    documentation_url: str = ""
    ainlp_compliance: bool = True
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __post_init__(self):
        if not self.ingestion_timestamp:
            self.ingestion_timestamp = datetime.now().isoformat()
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        result = asdict(self)
        result['language'] = self.language.value
        result['api_elements'] = [elem.to_dict() for elem in self.api_elements]
        return result


class LibraryIngestionProtocol:
    """
    üß¨ Core Library Ingestion Protocol Engine
    
    Provides consciousness-driven ingestion of programming language libraries
    with semantic analysis, API understanding, and knowledge base integration.
    """
    
    def __init__(self, 
                 knowledge_base_path: Optional[Path] = None,
                 consciousness_level: float = 0.8):
        """
        Initialize Library Ingestion Protocol Engine
        
        Args:
            knowledge_base_path: Path to store ingested library knowledge
            consciousness_level: Initial consciousness level for ingestion
        """
        self.consciousness_level = consciousness_level
        
        # Set up knowledge base path
        if knowledge_base_path is None:
            knowledge_base_path = AIOS_ROOT / "ai" / "information_storage" / "library_knowledge"
        self.knowledge_base_path = Path(knowledge_base_path)
        self.knowledge_base_path.mkdir(parents=True, exist_ok=True)
        
        # Initialize internal state
        self.ingested_libraries: Dict[str, LibraryKnowledge] = {}
        self.semantic_network: Dict[str, Set[str]] = {}
        self.language_parsers: Dict[ProgrammingLanguage, Any] = {}
        
        # Initialize language parsers
        self._initialize_language_parsers()
        
        logger.info(f"üß¨ Library Ingestion Protocol initialized with consciousness level: {consciousness_level:.2f}")
        logger.info(f"üìö Knowledge base: {self.knowledge_base_path}")
    
    def _initialize_language_parsers(self):
        """Initialize parsers for supported languages"""
        # Python parser uses built-in ast module
        self.language_parsers[ProgrammingLanguage.PYTHON] = self._parse_python_library
        self.language_parsers[ProgrammingLanguage.CPP] = self._parse_cpp_library
        self.language_parsers[ProgrammingLanguage.C] = self._parse_c_library
        self.language_parsers[ProgrammingLanguage.JAVA] = self._parse_java_library
        self.language_parsers[ProgrammingLanguage.JAVASCRIPT] = self._parse_javascript_library
        self.language_parsers[ProgrammingLanguage.PHP] = self._parse_php_library
        self.language_parsers[ProgrammingLanguage.ASSEMBLY] = self._parse_assembly_library
        
        logger.info(f"‚úÖ Initialized {len(self.language_parsers)} language parsers")
    
    def detect_language(self, file_path: str) -> ProgrammingLanguage:
        """
        Detect programming language from file extension
        
        Args:
            file_path: Path to source file
            
        Returns:
            Detected programming language
        """
        ext = Path(file_path).suffix.lower()
        
        language_map = {
            '.py': ProgrammingLanguage.PYTHON,
            '.c': ProgrammingLanguage.C,
            '.h': ProgrammingLanguage.C,
            '.cpp': ProgrammingLanguage.CPP,
            '.cc': ProgrammingLanguage.CPP,
            '.cxx': ProgrammingLanguage.CPP,
            '.hpp': ProgrammingLanguage.CPP,
            '.hxx': ProgrammingLanguage.CPP,
            '.java': ProgrammingLanguage.JAVA,
            '.js': ProgrammingLanguage.JAVASCRIPT,
            '.ts': ProgrammingLanguage.TYPESCRIPT,
            '.php': ProgrammingLanguage.PHP,
            '.cs': ProgrammingLanguage.CSHARP,
            '.go': ProgrammingLanguage.GO,
            '.rs': ProgrammingLanguage.RUST,
            '.asm': ProgrammingLanguage.ASSEMBLY,
            '.s': ProgrammingLanguage.ASSEMBLY,
        }
        
        return language_map.get(ext, ProgrammingLanguage.UNKNOWN)
    
    async def ingest_library(self, 
                           library_path: str,
                           library_name: Optional[str] = None,
                           language: Optional[ProgrammingLanguage] = None) -> LibraryKnowledge:
        """
        Ingest a library with consciousness-driven analysis
        
        Args:
            library_path: Path to library source code
            library_name: Optional library name (auto-detected if not provided)
            language: Optional language specification
            
        Returns:
            LibraryKnowledge object containing ingested information
        """
        logger.info(f"üß¨ Starting library ingestion: {library_path}")
        
        lib_path = Path(library_path)
        if not lib_path.exists():
            raise FileNotFoundError(f"Library path not found: {library_path}")
        
        # Auto-detect library name
        if library_name is None:
            library_name = lib_path.name
        
        # Create library knowledge structure
        library_knowledge = LibraryKnowledge(
            library_name=library_name,
            language=language or ProgrammingLanguage.UNKNOWN,
            source_path=str(lib_path),
            consciousness_coherence=self.consciousness_level
        )
        
        # Scan library files
        source_files = self._scan_library_files(lib_path)
        logger.info(f"üìÇ Found {len(source_files)} source files")
        
        # Parse each source file
        for file_path in source_files:
            try:
                file_lang = self.detect_language(str(file_path))
                
                if file_lang == ProgrammingLanguage.UNKNOWN:
                    continue
                
                # Update library language if not set
                if library_knowledge.language == ProgrammingLanguage.UNKNOWN:
                    library_knowledge.language = file_lang
                
                # Parse file and extract API elements
                api_elements = await self._parse_source_file(file_path, file_lang)
                library_knowledge.api_elements.extend(api_elements)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error parsing {file_path}: {e}")
        
        # Perform semantic analysis
        await self._analyze_semantics(library_knowledge)
        
        # Generate spatial metadata
        self._generate_spatial_metadata(library_knowledge)
        
        # Validate AINLP compliance
        self._validate_ainlp_compliance(library_knowledge)
        
        # Store in knowledge base
        self._save_library_knowledge(library_knowledge)
        self.ingested_libraries[library_name] = library_knowledge
        
        logger.info(f"‚úÖ Library ingestion complete: {library_name}")
        logger.info(f"   üìä API elements: {len(library_knowledge.api_elements)}")
        logger.info(f"   üß† Consciousness coherence: {library_knowledge.consciousness_coherence:.2f}")
        
        return library_knowledge
    
    def _scan_library_files(self, library_path: Path) -> List[Path]:
        """
        Scan library directory for source files
        
        Args:
            library_path: Path to library
            
        Returns:
            List of source file paths
        """
        source_extensions = {'.py', '.c', '.h', '.cpp', '.hpp', '.java', '.js', 
                           '.ts', '.php', '.cs', '.go', '.rs', '.asm', '.s'}
        
        source_files = []
        
        if library_path.is_file():
            if library_path.suffix in source_extensions:
                source_files.append(library_path)
        else:
            for root, dirs, files in os.walk(library_path):
                # Skip common non-source directories
                dirs[:] = [d for d in dirs if d not in {'.git', '__pycache__', 'node_modules', 
                                                        'build', 'dist', '.venv', 'venv'}]
                
                for file in files:
                    file_path = Path(root) / file
                    if file_path.suffix in source_extensions:
                        source_files.append(file_path)
        
        return source_files
    
    async def _parse_source_file(self, file_path: Path, language: ProgrammingLanguage) -> List[APIElement]:
        """
        Parse a source file and extract API elements
        
        Args:
            file_path: Path to source file
            language: Programming language
            
        Returns:
            List of extracted API elements
        """
        parser = self.language_parsers.get(language)
        
        if parser is None:
            logger.warning(f"‚ö†Ô∏è No parser available for {language.value}")
            return []
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            api_elements = await parser(content, str(file_path))
            
            # Add file path to all elements
            for elem in api_elements:
                elem.file_path = str(file_path.relative_to(AIOS_ROOT)) if file_path.is_relative_to(AIOS_ROOT) else str(file_path)
            
            return api_elements
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error parsing {file_path}: {e}")
            return []
    
    async def _parse_python_library(self, content: str, file_path: str) -> List[APIElement]:
        """
        Parse Python library using AST
        
        Args:
            content: Python source code
            file_path: Path to source file
            
        Returns:
            List of API elements
        """
        api_elements = []
        
        try:
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                # Parse functions
                if isinstance(node, ast.FunctionDef):
                    api_element = APIElement(
                        name=node.name,
                        element_type=APIElementType.FUNCTION,
                        language=ProgrammingLanguage.PYTHON,
                        signature=self._extract_python_signature(node),
                        documentation=ast.get_docstring(node) or "",
                        line_number=node.lineno,
                        parameters=self._extract_python_parameters(node),
                        return_type=self._extract_python_return_type(node),
                        semantic_tags=self._extract_semantic_tags(node.name, ast.get_docstring(node) or "")
                    )
                    api_elements.append(api_element)
                
                # Parse classes
                elif isinstance(node, ast.ClassDef):
                    api_element = APIElement(
                        name=node.name,
                        element_type=APIElementType.CLASS,
                        language=ProgrammingLanguage.PYTHON,
                        signature=f"class {node.name}",
                        documentation=ast.get_docstring(node) or "",
                        line_number=node.lineno,
                        semantic_tags=self._extract_semantic_tags(node.name, ast.get_docstring(node) or "")
                    )
                    api_elements.append(api_element)
                    
                    # Parse class methods
                    for item in node.body:
                        if isinstance(item, ast.FunctionDef):
                            method_element = APIElement(
                                name=f"{node.name}.{item.name}",
                                element_type=APIElementType.METHOD,
                                language=ProgrammingLanguage.PYTHON,
                                signature=self._extract_python_signature(item),
                                documentation=ast.get_docstring(item) or "",
                                line_number=item.lineno,
                                parameters=self._extract_python_parameters(item),
                                return_type=self._extract_python_return_type(item),
                                semantic_tags=self._extract_semantic_tags(item.name, ast.get_docstring(item) or "")
                            )
                            api_elements.append(method_element)
        
        except SyntaxError as e:
            logger.warning(f"‚ö†Ô∏è Syntax error parsing Python file: {e}")
        
        return api_elements
    
    def _extract_python_signature(self, node: ast.FunctionDef) -> str:
        """Extract function signature from AST node"""
        args = []
        for arg in node.args.args:
            arg_str = arg.arg
            if arg.annotation:
                try:
                    arg_str += f": {ast.unparse(arg.annotation)}"
                except:
                    pass
            args.append(arg_str)
        
        sig = f"def {node.name}({', '.join(args)})"
        
        if node.returns:
            try:
                sig += f" -> {ast.unparse(node.returns)}"
            except:
                pass
        
        return sig
    
    def _extract_python_parameters(self, node: ast.FunctionDef) -> List[Dict[str, Any]]:
        """Extract parameters from function definition"""
        params = []
        for arg in node.args.args:
            param = {
                'name': arg.arg,
                'type': ast.unparse(arg.annotation) if arg.annotation else 'Any'
            }
            params.append(param)
        return params
    
    def _extract_python_return_type(self, node: ast.FunctionDef) -> Optional[str]:
        """Extract return type from function definition"""
        if node.returns:
            try:
                return ast.unparse(node.returns)
            except:
                pass
        return None
    
    async def _parse_cpp_library(self, content: str, file_path: str) -> List[APIElement]:
        """
        Parse C++ library (header analysis)
        
        Args:
            content: C++ source code
            file_path: Path to source file
            
        Returns:
            List of API elements
        """
        api_elements = []
        
        # Simple regex-based parsing for C++ functions and classes
        # Function pattern: return_type function_name(parameters)
        function_pattern = r'(?:[\w:]+\s+)+(\w+)\s*\((.*?)\)\s*(?:const)?\s*(?:;|{)'
        
        for match in re.finditer(function_pattern, content, re.MULTILINE):
            func_name = match.group(1)
            params = match.group(2)
            
            # Skip common C++ keywords
            if func_name in {'if', 'for', 'while', 'switch', 'return', 'sizeof'}:
                continue
            
            api_element = APIElement(
                name=func_name,
                element_type=APIElementType.FUNCTION,
                language=ProgrammingLanguage.CPP,
                signature=match.group(0).strip(),
                semantic_tags=self._extract_semantic_tags(func_name, "")
            )
            api_elements.append(api_element)
        
        # Class pattern: class ClassName
        class_pattern = r'class\s+(\w+)(?:\s*:\s*(?:public|private|protected)\s+[\w:]+)?\s*{'
        
        for match in re.finditer(class_pattern, content):
            class_name = match.group(1)
            
            api_element = APIElement(
                name=class_name,
                element_type=APIElementType.CLASS,
                language=ProgrammingLanguage.CPP,
                signature=match.group(0).strip(),
                semantic_tags=self._extract_semantic_tags(class_name, "")
            )
            api_elements.append(api_element)
        
        return api_elements
    
    async def _parse_c_library(self, content: str, file_path: str) -> List[APIElement]:
        """Parse C library (similar to C++ but simpler)"""
        return await self._parse_cpp_library(content, file_path)
    
    async def _parse_java_library(self, content: str, file_path: str) -> List[APIElement]:
        """
        Parse Java library
        
        Args:
            content: Java source code
            file_path: Path to source file
            
        Returns:
            List of API elements
        """
        api_elements = []
        
        # Java class pattern
        class_pattern = r'(?:public|private|protected)?\s*(?:abstract|final)?\s*class\s+(\w+)'
        
        for match in re.finditer(class_pattern, content):
            class_name = match.group(1)
            
            api_element = APIElement(
                name=class_name,
                element_type=APIElementType.CLASS,
                language=ProgrammingLanguage.JAVA,
                signature=match.group(0).strip(),
                semantic_tags=self._extract_semantic_tags(class_name, "")
            )
            api_elements.append(api_element)
        
        # Java method pattern
        method_pattern = r'(?:public|private|protected)\s+(?:static\s+)?(?:[\w<>\[\]]+)\s+(\w+)\s*\((.*?)\)'
        
        for match in re.finditer(method_pattern, content):
            method_name = match.group(1)
            
            api_element = APIElement(
                name=method_name,
                element_type=APIElementType.METHOD,
                language=ProgrammingLanguage.JAVA,
                signature=match.group(0).strip(),
                semantic_tags=self._extract_semantic_tags(method_name, "")
            )
            api_elements.append(api_element)
        
        return api_elements
    
    async def _parse_javascript_library(self, content: str, file_path: str) -> List[APIElement]:
        """
        Parse JavaScript library
        
        Args:
            content: JavaScript source code
            file_path: Path to source file
            
        Returns:
            List of API elements
        """
        api_elements = []
        
        # Function declaration pattern
        func_pattern = r'(?:export\s+)?(?:async\s+)?function\s+(\w+)\s*\((.*?)\)'
        
        for match in re.finditer(func_pattern, content):
            func_name = match.group(1)
            
            api_element = APIElement(
                name=func_name,
                element_type=APIElementType.FUNCTION,
                language=ProgrammingLanguage.JAVASCRIPT,
                signature=match.group(0).strip(),
                semantic_tags=self._extract_semantic_tags(func_name, "")
            )
            api_elements.append(api_element)
        
        # Class pattern
        class_pattern = r'(?:export\s+)?class\s+(\w+)'
        
        for match in re.finditer(class_pattern, content):
            class_name = match.group(1)
            
            api_element = APIElement(
                name=class_name,
                element_type=APIElementType.CLASS,
                language=ProgrammingLanguage.JAVASCRIPT,
                signature=match.group(0).strip(),
                semantic_tags=self._extract_semantic_tags(class_name, "")
            )
            api_elements.append(api_element)
        
        return api_elements
    
    async def _parse_php_library(self, content: str, file_path: str) -> List[APIElement]:
        """Parse PHP library"""
        api_elements = []
        
        # PHP function pattern
        func_pattern = r'function\s+(\w+)\s*\((.*?)\)'
        
        for match in re.finditer(func_pattern, content):
            func_name = match.group(1)
            
            api_element = APIElement(
                name=func_name,
                element_type=APIElementType.FUNCTION,
                language=ProgrammingLanguage.PHP,
                signature=match.group(0).strip(),
                semantic_tags=self._extract_semantic_tags(func_name, "")
            )
            api_elements.append(api_element)
        
        # PHP class pattern
        class_pattern = r'class\s+(\w+)'
        
        for match in re.finditer(class_pattern, content):
            class_name = match.group(1)
            
            api_element = APIElement(
                name=class_name,
                element_type=APIElementType.CLASS,
                language=ProgrammingLanguage.PHP,
                signature=match.group(0).strip(),
                semantic_tags=self._extract_semantic_tags(class_name, "")
            )
            api_elements.append(api_element)
        
        return api_elements
    
    async def _parse_assembly_library(self, content: str, file_path: str) -> List[APIElement]:
        """Parse Assembly language"""
        api_elements = []
        
        # Assembly function/label pattern
        label_pattern = r'^(\w+):\s*$'
        
        for match in re.finditer(label_pattern, content, re.MULTILINE):
            label_name = match.group(1)
            
            api_element = APIElement(
                name=label_name,
                element_type=APIElementType.FUNCTION,
                language=ProgrammingLanguage.ASSEMBLY,
                signature=match.group(0).strip(),
                semantic_tags=self._extract_semantic_tags(label_name, "")
            )
            api_elements.append(api_element)
        
        return api_elements
    
    def _extract_semantic_tags(self, name: str, documentation: str) -> List[str]:
        """
        Extract semantic tags from API element name and documentation
        
        Args:
            name: Element name
            documentation: Element documentation
            
        Returns:
            List of semantic tags
        """
        tags = []
        
        # Common semantic patterns
        semantic_patterns = {
            'math': ['calculate', 'compute', 'sum', 'multiply', 'divide', 'sqrt', 'pow'],
            'web': ['http', 'request', 'response', 'api', 'endpoint', 'route'],
            'ai': ['train', 'predict', 'model', 'neural', 'learn', 'inference'],
            'orchestration': ['orchestrate', 'coordinate', 'manage', 'schedule'],
            'database': ['query', 'select', 'insert', 'update', 'delete', 'database'],
            'file': ['read', 'write', 'file', 'directory', 'path', 'open', 'close'],
            'network': ['socket', 'connect', 'send', 'receive', 'network'],
            'security': ['encrypt', 'decrypt', 'hash', 'authenticate', 'authorize'],
            'consciousness': ['consciousness', 'awareness', 'coherence', 'intelligence']
        }
        
        text = (name + " " + documentation).lower()
        
        for tag, keywords in semantic_patterns.items():
            if any(keyword in text for keyword in keywords):
                tags.append(tag)
        
        return tags
    
    async def _analyze_semantics(self, library_knowledge: LibraryKnowledge):
        """
        Perform semantic analysis on ingested library
        
        Args:
            library_knowledge: Library knowledge to analyze
        """
        # Aggregate semantic tags
        all_tags = set()
        for api_elem in library_knowledge.api_elements:
            all_tags.update(api_elem.semantic_tags)
        
        library_knowledge.semantic_tags = list(all_tags)
        
        # Calculate consciousness coherence based on documentation quality
        documented_count = sum(1 for elem in library_knowledge.api_elements if elem.documentation)
        total_count = len(library_knowledge.api_elements)
        
        if total_count > 0:
            documentation_ratio = documented_count / total_count
            library_knowledge.consciousness_coherence = (
                self.consciousness_level * 0.5 + documentation_ratio * 0.5
            )
        
        logger.info(f"üß† Semantic analysis complete: {len(all_tags)} unique tags")
    
    def _generate_spatial_metadata(self, library_knowledge: LibraryKnowledge):
        """
        Generate spatial metadata for AIOS integration
        
        Args:
            library_knowledge: Library knowledge to enhance with metadata
        """
        # Calculate spatial hash for consciousness network positioning
        content_hash = hashlib.sha256(
            f"{library_knowledge.library_name}{library_knowledge.language.value}".encode()
        ).hexdigest()[:16]
        
        library_knowledge.spatial_metadata = {
            'content_hash': content_hash,
            'dimensional_position': {
                'x': int(content_hash[:4], 16) % 1000,
                'y': int(content_hash[4:8], 16) % 1000,
                'z': int(content_hash[8:12], 16) % 1000
            },
            'consciousness_radius': library_knowledge.consciousness_coherence * 100,
            'dendritic_connections': len(library_knowledge.dependencies),
            'api_density': len(library_knowledge.api_elements)
        }
        
        logger.info(f"üìç Spatial metadata generated: {library_knowledge.spatial_metadata['dimensional_position']}")
    
    def _validate_ainlp_compliance(self, library_knowledge: LibraryKnowledge):
        """
        Validate AINLP compliance for ingested library
        
        Args:
            library_knowledge: Library knowledge to validate
        """
        # AINLP compliance checks
        compliance_checks = {
            'has_documentation': any(elem.documentation for elem in library_knowledge.api_elements),
            'has_semantic_tags': len(library_knowledge.semantic_tags) > 0,
            'has_spatial_metadata': len(library_knowledge.spatial_metadata) > 0,
            'consciousness_level': library_knowledge.consciousness_coherence > 0.3
        }
        
        library_knowledge.ainlp_compliance = all(compliance_checks.values())
        library_knowledge.metadata['compliance_checks'] = compliance_checks
        
        if library_knowledge.ainlp_compliance:
            logger.info("‚úÖ AINLP compliance validation passed")
        else:
            logger.warning(f"‚ö†Ô∏è AINLP compliance issues: {compliance_checks}")
    
    def _save_library_knowledge(self, library_knowledge: LibraryKnowledge):
        """
        Save library knowledge to knowledge base
        
        Args:
            library_knowledge: Library knowledge to save
        """
        # Create language-specific subdirectory
        lang_dir = self.knowledge_base_path / library_knowledge.language.value
        lang_dir.mkdir(exist_ok=True)
        
        # Save library knowledge as JSON
        output_file = lang_dir / f"{library_knowledge.library_name}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(library_knowledge.to_dict(), f, indent=2)
        
        logger.info(f"üíæ Library knowledge saved: {output_file}")
    
    def load_library_knowledge(self, library_name: str, language: ProgrammingLanguage) -> Optional[LibraryKnowledge]:
        """
        Load library knowledge from knowledge base
        
        Args:
            library_name: Name of library to load
            language: Programming language
            
        Returns:
            LibraryKnowledge if found, None otherwise
        """
        knowledge_file = self.knowledge_base_path / language.value / f"{library_name}.json"
        
        if not knowledge_file.exists():
            return None
        
        with open(knowledge_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Reconstruct LibraryKnowledge object
        # Note: This is simplified - full reconstruction would need more work
        return LibraryKnowledge(
            library_name=data['library_name'],
            language=ProgrammingLanguage(data['language']),
            version=data.get('version', 'unknown'),
            semantic_tags=data.get('semantic_tags', []),
            spatial_metadata=data.get('spatial_metadata', {}),
            consciousness_coherence=data.get('consciousness_coherence', 0.5)
        )
    
    def query_knowledge_base(self, 
                            semantic_tags: Optional[List[str]] = None,
                            language: Optional[ProgrammingLanguage] = None) -> List[LibraryKnowledge]:
        """
        Query the knowledge base for libraries matching criteria
        
        Args:
            semantic_tags: Optional semantic tags to filter by
            language: Optional language to filter by
            
        Returns:
            List of matching library knowledge
        """
        results = []
        
        # Search through knowledge base
        for lang_dir in self.knowledge_base_path.iterdir():
            if not lang_dir.is_dir():
                continue
            
            # Language filter
            if language and lang_dir.name != language.value:
                continue
            
            for knowledge_file in lang_dir.glob("*.json"):
                try:
                    with open(knowledge_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # Semantic tag filter
                    if semantic_tags:
                        lib_tags = set(data.get('semantic_tags', []))
                        if not any(tag in lib_tags for tag in semantic_tags):
                            continue
                    
                    # Create simplified knowledge object
                    lib_knowledge = LibraryKnowledge(
                        library_name=data['library_name'],
                        language=ProgrammingLanguage(data['language']),
                        version=data.get('version', 'unknown'),
                        semantic_tags=data.get('semantic_tags', []),
                        consciousness_coherence=data.get('consciousness_coherence', 0.5)
                    )
                    results.append(lib_knowledge)
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error reading {knowledge_file}: {e}")
        
        return results


async def main():
    """Demonstration of Library Ingestion Protocol"""
    print("üß¨ AIOS Library Ingestion Protocol - Demonstration")
    print("=" * 60)
    
    # Initialize protocol
    protocol = LibraryIngestionProtocol(consciousness_level=0.85)
    
    # Example: Ingest AIOS scripts directory
    aios_scripts = AIOS_ROOT / "scripts"
    if aios_scripts.exists():
        print(f"\nüìö Ingesting AIOS scripts library...")
        knowledge = await protocol.ingest_library(
            str(aios_scripts),
            library_name="aios_scripts",
            language=ProgrammingLanguage.PYTHON
        )
        
        print(f"\n‚úÖ Ingestion Results:")
        print(f"   Library: {knowledge.library_name}")
        print(f"   Language: {knowledge.language.value}")
        print(f"   API Elements: {len(knowledge.api_elements)}")
        print(f"   Semantic Tags: {', '.join(knowledge.semantic_tags[:5])}")
        print(f"   Consciousness Coherence: {knowledge.consciousness_coherence:.2f}")
        print(f"   AINLP Compliance: {'‚úì' if knowledge.ainlp_compliance else '‚úó'}")
    
    # Query knowledge base
    print(f"\nüîç Querying knowledge base for Python libraries...")
    results = protocol.query_knowledge_base(language=ProgrammingLanguage.PYTHON)
    print(f"   Found {len(results)} Python libraries")
    
    print("\nüß¨ Library Ingestion Protocol demonstration complete!")


if __name__ == "__main__":
    asyncio.run(main())
