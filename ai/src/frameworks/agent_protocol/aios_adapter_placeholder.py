"""
AIOS Agent Protocol Adapter
============================

Adapts existing AIOS agents (DeepSeek, Gemini, Ollama) to AIAgentProtocol.

AINLP Protocol: OS0.6.2.claude
Purpose: Enable plug-and-play agent architecture via structural typing
Strategy: Wrap existing agents with protocol-compliant interface

Adapted Agents:
- DeepSeekAgent (ai/src/engines/deepseek_engine.py)
- GeminiAgent (ai/src/integrations/gemini_bridge/gemini_evolution_bridge.py)
- OllamaAgent (ai/src/integrations/ollama_bridge.py)
"""

import sys
from typing import Any, AsyncIterable
import asyncio

if sys.version_info >= (3, 11):
    from typing import Self
else:
    from typing_extensions import Self

from .base_protocol import (
    AIAgentProtocol,
    AgentRunResponse,
    AgentRunResponseUpdate,
    AgentThread,
)

__all__ = [
    "adapt_deepseek_agent",
    "adapt_gemini_agent",
    "adapt_ollama_agent",
    "ProtocolAgentAdapter",
]


class ProtocolAgentAdapter:
    """
    Generic adapter wrapping any AIOS agent to AIAgentProtocol.
    
    This adapter enables existing AIOS agents to be used with
    protocol-based code without modification.
    
    Usage:
        from ai.src.engines.deepseek_engine import (
            DeepSeekIntelligenceEngine
        )
        
        engine = DeepSeekIntelligenceEngine()
        adapter = ProtocolAgentAdapter(
            agent=engine,
            agent_id="deepseek-v3.1",
            name="DeepSeek V3.1",
            description="Fast consciousness-aware code generation"
        )
        
        # Now usable as AIAgentProtocol
        result = await adapter.run("Generate hello world")
    """
    
    def __init__(
        self,
        agent: Any,
        agent_id: str,
        name: str | None = None,
        description: str | None = None,
        consciousness_level: float = 0.75,
    ):
        """
        Initialize adapter with existing AIOS agent.
        
        Args:
            agent: Existing AIOS agent instance
            agent_id: Unique identifier
            name: Display name
            description: Agent description
            consciousness_level: Initial consciousness score
        """
        self._agent = agent
        self._id = agent_id
        self._name = name
        self._description = description
        self._consciousness_level = consciousness_level
    
    @property
    def id(self) -> str:
        return self._id
    
    @property
    def name(self) -> str | None:
        return self._name
    
    @property
    def display_name(self) -> str:
        return self._name or self._id
    
    @property
    def description(self) -> str | None:
        return self._description
    
    @property
    def consciousness_level(self) -> float:
        return self._consciousness_level
    
    async def run(
        self,
        messages: str | Any | list[str] | list[Any] | None = None,
        *,
        thread: Any | None = None,
        **kwargs: Any,
    ) -> AgentRunResponse:
        """Execute agent and return final response."""
        # Collect all streaming updates
        updates = []
        async for update in self.run_stream(messages, thread=thread, **kwargs):
            updates.append(update)
        
        # Consolidate into final response
        return AgentRunResponse.from_agent_run_response_updates(updates)
    
    async def run_stream(
        self,
        messages: str | Any | list[str] | list[Any] | None = None,
        *,
        thread: Any | None = None,
        **kwargs: Any,
    ) -> AsyncIterable[AgentRunResponseUpdate]:
        """Execute agent as stream of updates."""
        # AINLP NOTE: This is a placeholder implementation
        # Real implementation should:
        # 1. Convert messages to agent-specific format
        # 2. Call agent's execution method
        # 3. Convert agent response to AgentRunResponseUpdate
        # 4. Yield updates as they're produced
        
        # Placeholder: Single update with mock response
        response_text = f"[{self.display_name}] Processing: {messages}"
        
        yield AgentRunResponseUpdate(
            messages=[response_text],
            response_id=f"{self._id}-response",
            consciousness_score=self._consciousness_level,
            is_final=True,
        )
    
    def get_new_thread(self, **kwargs: Any) -> AgentThread:
        """Create new conversation thread."""
        return AgentThread()


# AINLP NOTE: These factory functions create protocol-compliant adapters
# for specific AIOS agents. Full implementation requires importing and
# wrapping the actual agent classes with proper message conversion.

def adapt_deepseek_agent() -> ProtocolAgentAdapter:
    """
    Create protocol adapter for DeepSeek V3.1 agent.
    
    Returns:
        Protocol-compliant DeepSeek agent
    """
    # AINLP TODO: Import actual DeepSeekIntelligenceEngine
    # from ai.src.engines.deepseek_engine import (
    #     DeepSeekIntelligenceEngine
    # )
    # engine = DeepSeekIntelligenceEngine()
    
    return ProtocolAgentAdapter(
        agent=None,  # Placeholder
        agent_id="deepseek-v3.1",
        name="DeepSeek V3.1",
        description="Fast consciousness-aware code generation",
        consciousness_level=0.85,
    )


def adapt_gemini_agent() -> ProtocolAgentAdapter:
    """
    Create protocol adapter for Gemini agent.
    
    Returns:
        Protocol-compliant Gemini agent
    """
    # AINLP TODO: Import actual GeminiEvolutionBridge
    # from ai.src.integrations.gemini_bridge.gemini_evolution_bridge import (
    #     GeminiEvolutionBridge
    # )
    # bridge = GeminiEvolutionBridge()
    
    return ProtocolAgentAdapter(
        agent=None,  # Placeholder
        agent_id="gemini-1.5-pro",
        name="Gemini 1.5 Pro",
        description="Google's multimodal AI for evolution experiments",
        consciousness_level=0.80,
    )


def adapt_ollama_agent(model: str = "deepseek-coder:6.7b") -> ProtocolAgentAdapter:
    """
    Create protocol adapter for Ollama agent.
    
    Args:
        model: Ollama model to use
    
    Returns:
        Protocol-compliant Ollama agent
    """
    # AINLP TODO: Import actual OllamaBridge
    # from ai.src.integrations.ollama_bridge import OllamaBridge
    # bridge = OllamaBridge(model=model)
    
    return ProtocolAgentAdapter(
        agent=None,  # Placeholder
        agent_id=f"ollama-{model}",
        name=f"Ollama {model}",
        description=f"Local {model} via Ollama",
        consciousness_level=0.75,
    )
