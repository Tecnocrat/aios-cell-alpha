#!/usr/bin/env python3
"""
AIOS Unified Spatial Metadata System
Comprehensive spatial awareness with git-aware incremental updates

Location: ai/tools/aios_unified_spatial_metadata.py
Purpose: Unified tool combining full holographic metadata generation with 
         git-aware incremental updates for optimal performance and completeness.

Features:
- Full holographic metadata system creation
- Git-aware incremental updates
- Comprehensive architectural analysis
- Performance optimization
- Flexible CLI interface
"""

import os
import json
import subprocess
import sys
import logging
import argparse
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional, Set, Tuple

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('UnifiedSpatialMetadata')

class AIOSUnifiedSpatialMetadata:
    """
    Unified spatial metadata system combining comprehensive analysis with git-aware updates
    """
    
    def __init__(self, workspace_root: Path = None):
        self.workspace_root = workspace_root or Path(__file__).parents[2]
        self.metadata_filename = ".aios_spatial_metadata.json"
        self.holographic_index_file = "aios_holographic_index.json"
        
        # Configuration for metadata generation
        self.metadata_config = {
            "include_hidden": False,
            "max_file_depth": 10,
            "include_file_hashes": True,
            "include_content_analysis": True,
            "spatial_awareness_level": "detailed",
            "consciousness_integration": True
        }
        
        # File type categorization for AIOS consciousness
        self.file_categories = {
            "consciousness": [".py", ".ps1", ".cpp", ".cs", ".h", ".hpp"],
            "documentation": [".md", ".txt", ".rst", ".json", ".yaml", ".yml"],
            "configuration": [".json", ".yaml", ".yml", ".toml", ".ini", ".config"],
            "executable": [".exe", ".dll", ".so", ".bat", ".sh", ".ps1"],
            "archive": [".zip", ".tar", ".gz", ".7z", ".rar"],
            "temporary": [".tmp", ".temp", ".log", ".cache", ".bak"]
        }
        
        # AIOS architectural areas for spatial classification
        self.architectural_areas = {
            "githooks": ["GitHook Architecture", "Governance"],
            "ai": ["AI Intelligence Layer", "Consciousness"],
            "interface": ["Interface Layer", "UI Components"],
            "core": ["Core Engine", "System Foundation"],
            "docs": ["Documentation", "Knowledge Base"],
            "runtime_intelligence": ["Runtime Intelligence", "Monitoring"],
            "tachyonic": ["Tachyonic Archive", "Historical Data"],
            "visual_interface": ["Visual Interface", "User Experience"]
        }
        
        # Performance statistics
        self.stats = {
            "files_checked": 0,
            "metadata_created": 0,
            "metadata_updated": 0,
            "metadata_skipped": 0,
            "git_changed_files": 0,
            "start_time": datetime.now(timezone.utc)
        }
        
        logger.info("AIOS Unified Spatial Metadata System initialized")
        logger.info(f"Workspace: {self.workspace_root}")
        logger.info(f"Metadata file pattern: {self.metadata_filename}")
    
    # Git Integration Methods
    def get_git_changed_files(self, include_untracked: bool = True) -> Set[str]:
        """Get list of files that have changed according to git"""
        try:
            # Get modified and staged files
            result = subprocess.run(
                ["git", "diff", "--name-only", "HEAD"],
                cwd=self.workspace_root,
                capture_output=True,
                text=True,
                check=True
            )
            changed_files = set(result.stdout.strip().split('\n')) if result.stdout.strip() else set()
            
            # Get staged files
            result = subprocess.run(
                ["git", "diff", "--cached", "--name-only"],
                cwd=self.workspace_root,
                capture_output=True,
                text=True,
                check=True
            )
            if result.stdout.strip():
                changed_files.update(result.stdout.strip().split('\n'))
            
            # Get untracked files if requested
            if include_untracked:
                result = subprocess.run(
                    ["git", "ls-files", "--others", "--exclude-standard"],
                    cwd=self.workspace_root,
                    capture_output=True,
                    text=True,
                    check=True
                )
                if result.stdout.strip():
                    changed_files.update(result.stdout.strip().split('\n'))
            
            # Convert to absolute paths and filter out empty strings
            absolute_changed = set()
            for file_path in changed_files:
                if file_path:  # Skip empty strings
                    abs_path = (self.workspace_root / file_path).resolve()
                    absolute_changed.add(str(abs_path))
            
            self.stats["git_changed_files"] = len(absolute_changed)
            logger.info(f"Git detected {len(absolute_changed)} changed files")
            return absolute_changed
            
        except subprocess.CalledProcessError as e:
            logger.warning(f"Git command failed: {e}")
            return set()
    
    def get_affected_directories(self, changed_files: Set[str]) -> Set[Path]:
        """Get all directories that need metadata updates based on changed files"""
        affected_dirs = set()
        
        for file_path in changed_files:
            file_obj = Path(file_path)
            
            # Add the directory containing the file
            if file_obj.parent != self.workspace_root:
                affected_dirs.add(file_obj.parent)
            
            # Add all parent directories up to workspace root
            current = file_obj.parent
            while current != self.workspace_root and current.parent != current:
                affected_dirs.add(current)
                current = current.parent
        
        return affected_dirs
    
    def should_update_metadata(self, directory: Path, changed_files: Set[str] = None) -> bool:
        """Determine if a directory's metadata needs updating"""
        metadata_file = directory / self.metadata_filename
        
        # Always update if metadata doesn't exist
        if not metadata_file.exists():
            return True
        
        # If we have git change information, use it
        if changed_files:
            for file_path in changed_files:
                if str(directory) in str(file_path):
                    return True
        
        # Check if metadata file itself is outdated
        try:
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
                last_updated = metadata.get('metadata', {}).get('last_updated')
                if last_updated:
                    # Check if any files in directory are newer than metadata
                    metadata_time = datetime.fromisoformat(last_updated.replace('Z', '+00:00'))
                    for item in directory.iterdir():
                        if item.is_file() and item.stat().st_mtime > metadata_time.timestamp():
                            return True
        except (json.JSONDecodeError, KeyError, ValueError):
            return True  # Update if metadata is corrupted
        
        return False
    
    # Architectural Analysis Methods
    def _classify_architectural_area(self, relative_path: Path) -> Dict[str, Any]:
        """Classify folder into AIOS architectural areas"""
        
        path_parts = relative_path.parts
        primary_area = "unknown"
        secondary_areas = []
        
        for part in path_parts:
            part_lower = part.lower()
            for area_key, area_names in self.architectural_areas.items():
                if area_key in part_lower:
                    if primary_area == "unknown":
                        primary_area = area_names[0]
                    secondary_areas.extend(area_names)
        
        return {
            "primary_area": primary_area,
            "secondary_areas": list(set(secondary_areas)),
            "path_classification": list(path_parts),
            "consciousness_level": self._determine_consciousness_level(primary_area)
        }
    
    def _determine_consciousness_level(self, area: str) -> str:
        """Determine consciousness level based on architectural area"""
        consciousness_levels = {
            "AI Intelligence Layer": "high",
            "Consciousness": "highest",
            "GitHook Architecture": "high", 
            "Core Engine": "high",
            "Runtime Intelligence": "medium",
            "Interface Layer": "medium",
            "Documentation": "low",
            "unknown": "minimal"
        }
        return consciousness_levels.get(area, "minimal")
    
    def _analyze_spatial_context(self, folder_path: Path) -> Dict[str, Any]:
        """Analyze spatial relationships and context"""
        
        # Get immediate neighbors (siblings)
        siblings = []
        if folder_path.parent.exists():
            siblings = [p.name for p in folder_path.parent.iterdir() if p.is_dir() and p != folder_path]
        
        # Get children directories
        children = [p.name for p in folder_path.iterdir() if p.is_dir()] if folder_path.exists() else []
        
        # Calculate spatial metrics
        total_size = sum(f.stat().st_size for f in folder_path.rglob('*') if f.is_file()) if folder_path.exists() else 0
        file_count = len([f for f in folder_path.rglob('*') if f.is_file()]) if folder_path.exists() else 0
        
        return {
            "sibling_folders": sorted(siblings),
            "child_folders": sorted(children),
            "spatial_metrics": {
                "total_size_bytes": total_size,
                "file_count": file_count,
                "folder_count": len(children),
                "size_category": self._categorize_size(total_size)
            },
            "spatial_relationships": {
                "has_siblings": len(siblings) > 0,
                "has_children": len(children) > 0,
                "isolation_level": "isolated" if len(siblings) == 0 and len(children) == 0 else "connected"
            }
        }
    
    def _categorize_size(self, size_bytes: int) -> str:
        """Categorize folder size"""
        if size_bytes < 1024:
            return "tiny"
        elif size_bytes < 1024 * 1024:
            return "small" 
        elif size_bytes < 1024 * 1024 * 10:
            return "medium"
        elif size_bytes < 1024 * 1024 * 100:
            return "large"
        else:
            return "huge"
    
    def _analyze_folder_contents(self, folder_path: Path) -> Dict[str, Any]:
        """Analyze folder contents in detail"""
        
        if not folder_path.exists():
            return {"error": "Folder does not exist"}
        
        files_by_type = {}
        important_files = []
        recent_files = []
        
        try:
            for item in folder_path.iterdir():
                if item.is_file():
                    file_ext = item.suffix.lower()
                    file_type = self._categorize_file_type(file_ext)
                    
                    if file_type not in files_by_type:
                        files_by_type[file_type] = []
                    files_by_type[file_type].append(item.name)
                    
                    # Check if important
                    if self._is_important_file(item):
                        important_files.append(item.name)
                    
                    # Track recent files (last 30 days)
                    mtime = item.stat().st_mtime
                    if (datetime.now().timestamp() - mtime) < 30 * 24 * 3600:
                        recent_files.append({
                            "name": item.name,
                            "modified": datetime.fromtimestamp(mtime).isoformat()
                        })
        
        except PermissionError:
            logger.warning(f"Permission denied accessing {folder_path}")
            return {"error": "Permission denied"}
        
        return {
            "files_by_type": files_by_type,
            "important_files": important_files[:10],  # Limit to top 10
            "recent_files": sorted(recent_files, key=lambda x: x['modified'], reverse=True)[:10],
            "content_summary": {
                "total_files": len([f for f in folder_path.iterdir() if f.is_file()]),
                "file_types": list(files_by_type.keys()),
                "dominant_type": max(files_by_type.keys(), key=lambda k: len(files_by_type[k])) if files_by_type else None
            }
        }
    
    def _categorize_file_type(self, file_ext: str) -> str:
        """Categorize file by extension"""
        for category, extensions in self.file_categories.items():
            if file_ext in extensions:
                return category
        return "other"
    
    def _is_important_file(self, file_path: Path) -> bool:
        """Determine if file is important for AIOS context"""
        important_patterns = [
            "readme", "index", "main", "core", "aios", "consciousness", 
            "config", "setup", "init", "__init__", "package.json", 
            "requirements.txt", "cmakelists.txt", ".sln", ".csproj"
        ]
        
        file_name_lower = file_path.name.lower()
        return any(pattern in file_name_lower for pattern in important_patterns)
    
    def _calculate_consciousness_metrics(self, folder_path: Path) -> Dict[str, Any]:
        """Calculate AIOS consciousness metrics for the folder"""
        
        consciousness_indicators = {
            "ai_files": 0,
            "consciousness_files": 0,
            "agentic_files": 0,
            "intelligence_files": 0
        }
        
        consciousness_keywords = {
            "ai_files": ["ai", "artificial", "intelligence"],
            "consciousness_files": ["consciousness", "aware", "cognitive"],
            "agentic_files": ["agentic", "agent", "autonomous"],
            "intelligence_files": ["intelligence", "smart", "neural"]
        }
        
        if folder_path.exists():
            for file_path in folder_path.rglob('*'):
                if file_path.is_file():
                    filename = file_path.name.lower()
                    for indicator, keywords in consciousness_keywords.items():
                        if any(keyword in filename for keyword in keywords):
                            consciousness_indicators[indicator] += 1
        
        # Calculate consciousness score (0-100)
        total_files = sum(consciousness_indicators.values())
        consciousness_score = min(total_files * 10, 100) if total_files > 0 else 0
        
        return {
            "consciousness_indicators": consciousness_indicators,
            "consciousness_score": consciousness_score,
            "consciousness_level": "high" if consciousness_score > 50 else "medium" if consciousness_score > 20 else "low"
        }
    
    def _generate_navigation_aids(self, folder_path: Path) -> Dict[str, Any]:
        """Generate navigation aids for AI engines"""
        
        # Find key entry points
        entry_points = []
        config_files = []
        
        if folder_path.exists():
            for item in folder_path.iterdir():
                if item.is_file():
                    if item.name.lower() in ['main.py', '__init__.py', 'index.js', 'app.py']:
                        entry_points.append(item.name)
                    if any(pattern in item.name.lower() for pattern in ['config', 'settings', '.env']):
                        config_files.append(item.name)
        
        # Generate relative path to workspace root
        try:
            breadcrumb = " > ".join(folder_path.relative_to(self.workspace_root).parts)
        except ValueError:
            breadcrumb = str(folder_path)
        
        return {
            "entry_points": entry_points,
            "config_files": config_files,
            "breadcrumb_path": breadcrumb,
            "quick_commands": {
                "list_files": f"Get-ChildItem '{folder_path}' -Recurse",
                "find_python": f"Get-ChildItem '{folder_path}' -Recurse -Filter '*.py'",
                "find_scripts": f"Get-ChildItem '{folder_path}' -Recurse -Filter '*.ps1'"
            }
        }
    
    def _generate_ai_guidance(self, folder_path: Path, relative_path: Path) -> Dict[str, Any]:
        """Generate specific AI guidance for this folder"""
        
        folder_name = folder_path.name.lower()
        path_parts = relative_path.parts
        
        # Generate context-aware guidance
        guidance = {
            "primary_focus": "General development",
            "recommended_actions": [],
            "important_considerations": [],
            "related_folders": []
        }
        
        # GitHook-specific guidance
        if "githooks" in str(relative_path).lower():
            guidance.update({
                "primary_focus": "Git workflow automation and governance",
                "recommended_actions": [
                    "Maintain separation between pre-commit, commit-msg, and pre-push hooks",
                    "Test hook logic thoroughly before deployment",
                    "Ensure hooks are performant and don't slow down development",
                    "Document hook behavior for team members"
                ],
                "important_considerations": [
                    "Hooks run in restricted environment",
                    "Error handling is critical for user experience",
                    "Cross-platform compatibility required"
                ]
            })
        
        elif "ai" in str(relative_path).lower():
            guidance.update({
                "primary_focus": "AI consciousness and intelligence development",
                "recommended_actions": [
                    "Maintain clear separation between consciousness levels",
                    "Implement proper error handling for AI operations",
                    "Document AI behavior and decision-making logic",
                    "Test AI components in isolation"
                ],
                "important_considerations": [
                    "AI components should be modular and testable",
                    "Performance monitoring is essential",
                    "Version control AI model changes carefully"
                ]
            })
        
        elif "interface" in str(relative_path).lower():
            guidance.update({
                "primary_focus": "User interface and service layer development",
                "recommended_actions": [
                    "Separate UI logic from business logic",
                    "Implement proper error handling and user feedback",
                    "Ensure responsive design principles"
                ]
            })
        
        # Find related folders
        for part in path_parts:
            for area_key in self.architectural_areas.keys():
                if area_key in part.lower():
                    related = [f for f in self.workspace_root.glob(f"*{area_key}*") if f.is_dir() and f != folder_path]
                    guidance["related_folders"].extend([r.name for r in related[:3]])
        
        return guidance
    
    # Metadata Generation Methods
    def generate_folder_metadata(self, folder_path: Path, lightweight: bool = False) -> Dict[str, Any]:
        """Generate comprehensive metadata for a specific folder"""
        
        if not folder_path.exists() or not folder_path.is_dir():
            raise ValueError(f"Invalid folder path: {folder_path}")
        
        logger.info(f"Generating metadata for: {folder_path}")
        
        # Basic folder information
        relative_path = folder_path.relative_to(self.workspace_root)
        folder_name = folder_path.name
        
        # Create base metadata structure
        metadata = {
            "spatial_metadata_version": "2.0.0",
            "generation_timestamp": datetime.now(timezone.utc).isoformat(),
            "folder_info": {
                "name": folder_name,
                "absolute_path": str(folder_path.absolute()),
                "relative_path": str(relative_path),
                "parent_path": str(folder_path.parent.relative_to(self.workspace_root)) if folder_path.parent != self.workspace_root else "",
                "depth_level": len(relative_path.parts)
            },
            "architectural_classification": self._classify_architectural_area(relative_path),
            "spatial_context": self._analyze_spatial_context(folder_path),
            "content_analysis": self._analyze_folder_contents(folder_path),
        }
        
        # Add comprehensive analysis if not lightweight
        if not lightweight:
            metadata.update({
                "consciousness_metrics": self._calculate_consciousness_metrics(folder_path),
                "navigation_aids": self._generate_navigation_aids(folder_path),
                "ai_guidance": self._generate_ai_guidance(folder_path, relative_path)
            })
        
        # Add metadata info
        metadata["metadata"] = {
            "created": datetime.now(timezone.utc).isoformat(),
            "last_updated": datetime.now(timezone.utc).isoformat(),
            "generator_version": "2.0.0-unified",
            "git_aware": True,
            "lightweight_mode": lightweight
        }
        
        return metadata
    
    def create_holographic_metadata(self, target_folder: Path = None, overwrite: bool = False, lightweight: bool = False) -> Dict[str, str]:
        """Create holographic metadata file for a specific folder"""
        
        if target_folder is None:
            target_folder = self.workspace_root
        
        if not target_folder.exists():
            logger.error(f"Target folder does not exist: {target_folder}")
            return {}
        
        # Check if metadata already exists
        metadata_file = target_folder / self.metadata_filename
        if metadata_file.exists() and not overwrite:
            logger.info(f"Metadata already exists (use --overwrite): {target_folder}")
            return {"status": "skipped", "path": str(metadata_file)}
        
        logger.info(f"Creating holographic metadata for: {target_folder}")
        
        try:
            metadata = self.generate_folder_metadata(target_folder, lightweight)
            
            # If file exists and not forcing, try to preserve creation date
            if metadata_file.exists() and not overwrite:
                try:
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        existing = json.load(f)
                        if 'metadata' in existing and 'created' in existing['metadata']:
                            metadata['metadata']['created'] = existing['metadata']['created']
                except (json.JSONDecodeError, KeyError):
                    pass
            
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            logger.info(f"Holographic metadata {'updated' if overwrite else 'created'}: {metadata_file}")
            return {"status": "created" if not metadata_file.exists() else "updated", "path": str(metadata_file)}
            
        except Exception as e:
            logger.error(f"❌ Failed to create metadata for {target_folder}: {e}")
            return {"status": "error", "error": str(e)}
    
    def scan_and_create_holographic_system(self, max_depth: int = 3, overwrite: bool = False, lightweight: bool = False) -> Dict[str, Any]:
        """Scan workspace and create holographic metadata system"""
        
        logger.info("Creating AIOS Holographic Metadata System...")
        logger.info(f"Max depth: {max_depth}")
        logger.info(f"Overwrite mode: {overwrite}")
        logger.info(f"Lightweight mode: {lightweight}")
        
        created_files = {}
        updated_files = {}
        skipped_files = {}
        folder_count = 0
        processed_count = 0
        
        # Scan and create metadata for relevant folders
        for folder in self.workspace_root.rglob('*'):
            if folder.is_dir() and self._should_create_metadata(folder):
                folder_count += 1
                relative_path = folder.relative_to(self.workspace_root)
                
                # Check depth
                if len(relative_path.parts) > max_depth:
                    continue
                
                processed_count += 1
                result = self.create_holographic_metadata(folder, overwrite, lightweight)
                
                if result.get("status") == "created":
                    created_files[str(relative_path)] = result["path"]
                    self.stats["metadata_created"] += 1
                elif result.get("status") == "updated":
                    updated_files[str(relative_path)] = result["path"]
                    self.stats["metadata_updated"] += 1
                else:
                    skipped_files[str(relative_path)] = result.get("path", "")
                    self.stats["metadata_skipped"] += 1
        
        # Combine all files for total count
        all_files = {**created_files, **updated_files, **skipped_files}
        
        # Create master holographic index
        self._create_holographic_index(max_depth, overwrite, lightweight, created_files, updated_files, skipped_files, folder_count, processed_count)
        
        # Report results
        logger.info("Holographic Metadata System operation complete!")
        logger.info(f"Statistics:")
        logger.info(f"   Folders scanned: {folder_count}")
        logger.info(f"   Folders processed: {processed_count}")
        logger.info(f"   Metadata created: {len(created_files)}")
        logger.info(f"   Metadata updated: {len(updated_files)}")
        logger.info(f"   Metadata skipped: {len(skipped_files)}")
        logger.info(f"   Total metadata files: {len(all_files)}")
        
        return {
            "system_stats": {
                "folders_scanned": folder_count,
                "folders_processed": processed_count,
                "metadata_files_created": len(created_files),
                "metadata_files_updated": len(updated_files),
                "metadata_files_skipped": len(skipped_files),
                "total_metadata_files": len(all_files),
                "coverage_percentage": (len(all_files) / max(folder_count, 1)) * 100 if folder_count > 0 else 0
            },
            "metadata_files": {
                "created": created_files,
                "updated": updated_files,
                "skipped": skipped_files,
                "all_files": all_files
            }
        }
    
    def _should_create_metadata(self, folder: Path) -> bool:
        """Determine if we should create metadata for this folder"""
        
        # Skip hidden folders (except .githooks)
        if folder.name.startswith('.') and folder.name not in ['.githooks']:
            return False
        
        # Skip common build/temp folders
        skip_folders = {
            'node_modules', 'build', 'dist', 'target', 'bin', 'obj', 
            '__pycache__', '.vs', '.vscode', '.git', 'packages',
            'Debug', 'Release', 'x64', 'x86'
        }
        if folder.name in skip_folders:
            return False
        
        # Skip if parent is a skip folder
        for parent in folder.parents:
            if parent.name in skip_folders:
                return False
        
        # Must contain actual content
        try:
            has_files = any(item.is_file() for item in folder.iterdir())
            has_subdirs = any(item.is_dir() for item in folder.iterdir())
            return has_files or has_subdirs
        except PermissionError:
            return False
    
    def _create_holographic_index(self, max_depth, overwrite, lightweight, created_files, updated_files, skipped_files, folder_count, processed_count):
        """Create the master holographic index"""
        
        all_files = {**created_files, **updated_files, **skipped_files}
        
        index_data = {
            "holographic_system_version": "2.0.0",
            "creation_timestamp": datetime.now(timezone.utc).isoformat(),
            "workspace_root": str(self.workspace_root),
            "generation_parameters": {
                "max_depth": max_depth,
                "overwrite_mode": overwrite,
                "lightweight_mode": lightweight
            },
            "metadata_files": {
                "created": created_files,
                "updated": updated_files,
                "skipped": skipped_files,
                "all_files": all_files
            },
            "system_stats": {
                "folders_scanned": folder_count,
                "folders_processed": processed_count,
                "metadata_files_created": len(created_files),
                "metadata_files_updated": len(updated_files),
                "metadata_files_skipped": len(skipped_files),
                "total_metadata_files": len(all_files),
                "coverage_percentage": (len(all_files) / max(folder_count, 1)) * 100 if folder_count > 0 else 0
            },
            "performance_stats": self.stats,
            "usage_instructions": {
                "for_ai_engines": "Read .aios_spatial_metadata.json in each folder for spatial awareness",
                "chat_mode_integration": "Always check spatial metadata before creating files or folders",
                "spatial_awareness": "Use metadata to understand folder relationships and context",
                "incremental_updates": "Use --incremental flag for git-aware updates",
                "lightweight_mode": "Use --lightweight flag for faster generation with less detail"
            }
        }
        
        # Save master index
        index_file = self.workspace_root / self.holographic_index_file
        try:
            with open(index_file, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, indent=2, ensure_ascii=False)
            logger.info(f"Holographic index created: {index_file}")
        except Exception as e:
            logger.error(f"❌ Failed to create holographic index: {e}")
    
    # Incremental Update Methods
    def run_incremental_update(self, force: bool = False, dry_run: bool = False, lightweight: bool = False) -> Dict:
        """Run incremental spatial metadata update"""
        logger.info("Starting incremental spatial metadata update...")
        
        # Get changed files from git
        changed_files = self.get_git_changed_files()
        
        if not changed_files and not force:
            logger.info("No changes detected by git. Use --force to update all metadata.")
            return self.stats
        
        # Get affected directories
        affected_dirs = self.get_affected_directories(changed_files)
        logger.info(f"Found {len(affected_dirs)} directories affected by changes")
        
        updated_directories = []
        
        for directory in affected_dirs:
            self.stats["files_checked"] += 1
            
            if force or self.should_update_metadata(directory, changed_files):
                if dry_run:
                    logger.info(f"Would update: {directory}")
                    continue
                
                logger.info(f"Updating metadata for: {directory}")
                result = self.create_holographic_metadata(directory, overwrite=True, lightweight=lightweight)
                if result.get("status") in ["created", "updated"]:
                    updated_directories.append(directory)
            else:
                self.stats["metadata_skipped"] += 1
                logger.debug(f"Skipped (up to date): {directory}")
        
        if not dry_run and updated_directories:
            self._update_incremental_index(updated_directories)
        
        # Calculate execution time
        self.stats["execution_time"] = (
            datetime.now(timezone.utc) - self.stats["start_time"]
        ).total_seconds()
        
        # Log summary
        logger.info("Incremental update completed:")
        logger.info(f"  Files checked: {self.stats['files_checked']}")
        logger.info(f"  Metadata created: {self.stats['metadata_created']}")
        logger.info(f"  Metadata updated: {self.stats['metadata_updated']}")
        logger.info(f"  Metadata skipped: {self.stats['metadata_skipped']}")
        logger.info(f"  Execution time: {self.stats['execution_time']:.2f}s")
        
        return self.stats
    
    def _update_incremental_index(self, updated_directories: List[Path]):
        """Update the holographic index for incremental updates"""
        index_file = self.workspace_root / self.holographic_index_file
        
        # Load existing index or create new one
        if index_file.exists():
            try:
                with open(index_file, 'r', encoding='utf-8') as f:
                    index = json.load(f)
            except (json.JSONDecodeError, FileNotFoundError):
                index = {}
        else:
            index = {}
        
        # Update index structure
        index.update({
            "holographic_index": {
                "version": "2.0.0",
                "last_updated": datetime.now(timezone.utc).isoformat(),
                "workspace_root": str(self.workspace_root),
                "last_operation": "incremental_update",
                "directories_updated": len(updated_directories)
            },
            "incremental_update": {
                "last_update": datetime.now(timezone.utc).isoformat(),
                "updated_directories": [str(d.relative_to(self.workspace_root)) for d in updated_directories],
                "git_aware": True,
                "stats": {
                    "files_checked": self.stats["files_checked"],
                    "metadata_created": self.stats["metadata_created"], 
                    "metadata_updated": self.stats["metadata_updated"],
                    "metadata_skipped": self.stats["metadata_skipped"],
                    "git_changed_files": self.stats["git_changed_files"],
                    "start_time": self.stats["start_time"].isoformat(),
                    "execution_time": self.stats.get("execution_time", 0)
                }
            }
        })
        
        # Write updated index
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump(index, f, indent=2, ensure_ascii=False)
    
    # Utility Methods
    def read_spatial_metadata(self, folder_path: Path) -> Optional[Dict[str, Any]]:
        """Read spatial metadata for a specific folder"""
        
        metadata_file = folder_path / self.metadata_filename
        if not metadata_file.exists():
            logger.warning(f"⚠️ No spatial metadata found: {metadata_file}")
            return None
        
        try:
            with open(metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"❌ Failed to read metadata: {e}")
            return None

def main():
    """CLI entry point for unified spatial metadata system"""
    parser = argparse.ArgumentParser(description='AIOS Unified Spatial Metadata System')
    
    # Operation modes
    parser.add_argument('--create-system', action='store_true', help='Create full holographic system')
    parser.add_argument('--incremental', action='store_true', help='Run git-aware incremental update')
    parser.add_argument('--create-folder', type=Path, help='Create metadata for specific folder')
    parser.add_argument('--read-metadata', type=Path, help='Read metadata for specific folder')
    
    # Configuration options
    parser.add_argument('--max-depth', type=int, default=3, help='Maximum folder depth to process')
    parser.add_argument('--overwrite', action='store_true', help='Overwrite existing metadata files')
    parser.add_argument('--force', action='store_true', help='Force update all metadata (incremental mode)')
    parser.add_argument('--dry-run', action='store_true', help='Show what would be updated without making changes')
    parser.add_argument('--lightweight', action='store_true', help='Generate lightweight metadata (faster, less detail)')
    
    # General options
    parser.add_argument('--workspace', type=Path, help='AIOS workspace root')
    parser.add_argument('--verbose', '-v', action='store_true', help='Enable verbose logging')
    
    args = parser.parse_args()
    
    # Set logging level
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Initialize system
    workspace_root = Path(args.workspace).resolve() if args.workspace else None
    system = AIOSUnifiedSpatialMetadata(workspace_root)
    
    # Execute requested operation
    if args.create_system:
        result = system.scan_and_create_holographic_system(args.max_depth, args.overwrite, args.lightweight)
        print(f"\nHolographic System {'Updated' if args.overwrite else 'Created'}!")
        print(f"Created: {result['system_stats']['metadata_files_created']}")
        print(f"Updated: {result['system_stats']['metadata_files_updated']}")
        print(f"Skipped: {result['system_stats']['metadata_files_skipped']}")
        print(f"Total: {result['system_stats']['total_metadata_files']}")
        
    elif args.incremental:
        stats = system.run_incremental_update(args.force, args.dry_run, args.lightweight)
        if args.dry_run:
            print("\nDry run completed - no changes made")
        else:
            print(f"\nIncremental update completed!")
            print(f"Checked: {stats['files_checked']}")
            print(f"Created: {stats['metadata_created']}")
            print(f"Updated: {stats['metadata_updated']}")
            print(f"Skipped: {stats['metadata_skipped']}")
            print(f"Time: {stats.get('execution_time', 0):.2f}s")
        
    elif args.create_folder:
        result = system.create_holographic_metadata(args.create_folder, args.overwrite, args.lightweight)
        if result.get("status") in ["created", "updated"]:
            print(f"[SUCCESS] Metadata {result['status']} for: {args.create_folder}")
        else:
            print(f"[ERROR] Failed to create metadata for: {args.create_folder}")
            
    elif args.read_metadata:
        metadata = system.read_spatial_metadata(args.read_metadata)
        if metadata:
            print(json.dumps(metadata, indent=2))
        else:
            print(f"[ERROR] No metadata found for: {args.read_metadata}")
        
    else:
        print("AIOS Unified Spatial Metadata System")
        print("  --create-system     Generate full holographic metadata")
        print("  --incremental       Git-aware incremental updates")
        print("  --create-folder     Create metadata for specific folder")
        print("  --read-metadata     Read folder metadata")
        print("  --lightweight       Faster generation with less detail")
        print("  --dry-run           Preview changes without making them")
        print("  --overwrite         Update existing metadata files")
        print("  --verbose           Detailed logging")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())